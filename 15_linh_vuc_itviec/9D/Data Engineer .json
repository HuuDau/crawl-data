[
  {
    "title": "Senior Data Engineer",
    "company": "Creative Force",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Denmark",
    "company_model": "Sản phẩm",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Sản Phẩm Phần Mềm và Dịch Vụ Web",
    "createdAt": " Đăng 1 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are looking for a Senior Data Engineer with a strong technical background in data engineering and a proactive problem-solver with excellent communication skills. You should have a proven ability to build and maintain scalable data architectures and be comfortable working in a dynamic, fast-paced environment. The ideal candidate is passionate about optimizing data pipelines, has strong analytical skills, and is experienced in cloud infrastructure and big data technologies. You thrive in collaborative settings and enjoy working on complex data challenges that enable data-driven decision-making across the organization.",
      "We are looking for a Senior Data Engineer with a strong technical background in data engineering and a proactive problem-solver with excellent communication skills. You should have a proven ability to build and maintain scalable data architectures and be comfortable working in a dynamic, fast-paced environment. The ideal candidate is passionate about optimizing data pipelines, has strong analytical skills, and is experienced in cloud infrastructure and big data technologies. You thrive in collaborative settings and enjoy working on complex data challenges that enable data-driven decision-making across the organization.",
      "Senior Data Engineer",
      " ",
      "Responsibilities",
      "Responsibilities",
      "Responsibilities",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.\nCollaborate with internal teams and external customers to understand data needs and provide high-performance solutions.\nManage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.\nImplement and monitor data quality and integrity checks throughout the data lifecycle.\nBuild and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.",
      "Collaborate with internal teams and external customers to understand data needs and provide high-performance solutions.",
      "Collaborate with internal teams and external customers to understand data needs and provide high-performance solutions.",
      "Manage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.",
      "Manage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.",
      "Implement and monitor data quality and integrity checks throughout the data lifecycle.",
      "Implement and monitor data quality and integrity checks throughout the data lifecycle.",
      "Build and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Build and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Other responsibilities:",
      "Other responsibilities:",
      "Other responsibilities:",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.\nProvide expertise in designing and optimizing distributed data architectures.\nEnsure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.\nDrive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.\nLead the development of new tools and techniques to enhance the organization’s data capabilities.",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.",
      "Provide expertise in designing and optimizing distributed data architectures.",
      "Provide expertise in designing and optimizing distributed data architectures.",
      "Ensure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.",
      "Ensure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.",
      "Drive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.",
      "Drive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.",
      "Lead the development of new tools and techniques to enhance the organization’s data capabilities.",
      "Lead the development of new tools and techniques to enhance the organization’s data capabilities."
    ],
    "yc": [
      "Yêu cầu công việc",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.\nStrong technical expertise in database management, statistical analysis, and data visualization.\nStrong knowledge and experience in ETL processes.\nExperience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).\nExperience in managing large-scale databases and optimizing query performance.\nExperience with operational tools like Airflow, Debezium, or Kafka.\nCloud infrastructure and operations (AWS, GCP).\nExperience in Python or another programming language.\nExperience with cloud data warehousing solutions such as Google BigQuery or Snowflake\nHigh-level written and verbal communication skills in English.",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.",
      "Strong technical expertise in database management, statistical analysis, and data visualization.",
      "Strong technical expertise in database management, statistical analysis, and data visualization.",
      "Strong knowledge and experience in ETL processes.",
      "Strong knowledge and experience in ETL processes.",
      "Experience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).",
      "Experience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).",
      "Experience in managing large-scale databases and optimizing query performance.",
      "Experience in managing large-scale databases and optimizing query performance.",
      "Experience with operational tools like Airflow, Debezium, or Kafka.",
      "Experience with operational tools like Airflow, Debezium, or Kafka.",
      "Cloud infrastructure and operations (AWS, GCP).",
      "Cloud infrastructure and operations (AWS, GCP).",
      "Experience in Python or another programming language.",
      "Experience in Python or another programming language.",
      "Experience with cloud data warehousing solutions such as Google BigQuery or Snowflake",
      "Experience with cloud data warehousing solutions such as Google BigQuery or Snowflake",
      "High-level written and verbal communication skills in English.",
      "High-level written and verbal communication skills in English."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-creative-force-5121?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 2nd Floor, Detech II Tower, 107 Nguyen Phong Sac Str, Cau Giay, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "SQL",
      "Cloud"
    ]
  },
  {
    "title": "Data Engineer (Data Analyst, Python, Java, SQL)",
    "company": "VietinBank",
    "salary_range": "Very attractive!!!",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 1 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ Big Data: Hadoop ecosystem, Kafka, Spark, Airflow, …\nNghiên cứu, xây dựng, tối ưu các Job ETL có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ingest, tổng hợp các loại dữ liệu từ nhiều nguồn khác nhau;\nQuy hoạch, thiết kế các công cụ nền tảng, công cụ giám sát, cảnh báo KPI chất lượng số liệu… để tự động giám sát hiện trạng của hệ thống, chất lượng dữ liệu giúp đưa ra các cảnh báo kịp cho team\nNghiên cứu và quy hoạch các công cụ khai thác, phân tích số liệu (Big Data OLAP, Notebook …)",
      "Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ Big Data: Hadoop ecosystem, Kafka, Spark, Airflow, …",
      "Nghiên cứu, xây dựng, tối ưu các Job ETL có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ingest, tổng hợp các loại dữ liệu từ nhiều nguồn khác nhau;",
      "Quy hoạch, thiết kế các công cụ nền tảng, công cụ giám sát, cảnh báo KPI chất lượng số liệu… để tự động giám sát hiện trạng của hệ thống, chất lượng dữ liệu giúp đưa ra các cảnh báo kịp cho team",
      "Nghiên cứu và quy hoạch các công cụ khai thác, phân tích số liệu (Big Data OLAP, Notebook …)"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp ĐH chuyên ngành: Khoa học dữ liệu, Khoa học máy tính, CNTT, Toán học ứng dụng, hoặc chuyên ngành khác liên quan;\nThành thạo các ngôn ngữ truy vấn CSDL như SQL và NoSQL .\nKiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, ElasticSearch, Kafka, …)\nKiến thức về xây dựng, tối ưu luồng xử lý dữ liệu (batch processing, stream procesing, …);\nKỹ năng sử dụng ngôn ngữ lập trình (Java, Python, Scala, …);\nCó chứng chỉ quốc tế về Data Enginner (AWS, CCA, CCP, IBM Certified Data Engineer, Google Professional Data Engineer …) là một lợi thế\nTư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.",
      "Tốt nghiệp ĐH chuyên ngành: Khoa học dữ liệu, Khoa học máy tính, CNTT, Toán học ứng dụng, hoặc chuyên ngành khác liên quan;",
      "Thành thạo các ngôn ngữ truy vấn CSDL như SQL và NoSQL .",
      "Kiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, ElasticSearch, Kafka, …)",
      "Kiến thức về xây dựng, tối ưu luồng xử lý dữ liệu (batch processing, stream procesing, …);",
      "Kỹ năng sử dụng ngôn ngữ lập trình (Java, Python, Scala, …);",
      "Có chứng chỉ quốc tế về Data Enginner (AWS, CCA, CCP, IBM Certified Data Engineer, Google Professional Data Engineer …) là một lợi thế",
      "Tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineer-data-analyst-python-java-sql-vietinbank-4948?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 187 Nguyễn Lương Bằng , Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "Python",
      "SQL"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Hubble Pte. Ltd",
    "salary_range": "1,000 - 3,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Singapore",
    "company_model": "Sản phẩm",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Bất Động Sản và Xây Dựng",
    "createdAt": " Đăng 5 ngày trước",
    "description": [
      "Mô tả công việc",
      "What you will be doing:",
      "What you will be doing:",
      "Lead the maintenance and development of Hubble’s Data Warehouse and Data pipeline.\nWork with various ETL/ELT pipelines from various data sources.\nCollaborate with product managers and backend engineers to ensure that any changes in the products are accounted for in the data pipelines.\nCollaborate with the DevOps team to ensure that the cost of data processing and storage is optimized for the needs of the company.\nEnsure that the various data products and services are performant and reliable.",
      "Lead the maintenance and development of Hubble’s Data Warehouse and Data pipeline.",
      "Work with various ETL/ELT pipelines from various data sources.",
      "Collaborate with product managers and backend engineers to ensure that any changes in the products are accounted for in the data pipelines.",
      "Collaborate with the DevOps team to ensure that the cost of data processing and storage is optimized for the needs of the company.",
      "Ensure that the various data products and services are performant and reliable."
    ],
    "yc": [
      "Yêu cầu công việc",
      "What we need from you:",
      "What we need from you:",
      "4-5 years experience as a Data Engineer\nExperience working with cloud infrastructure such as Azure, AWS, or GCP.\nExperience working with data processing tools such as Apache Spark, Hadoop, Flink, Snowflake.\nExperience in SQL and Python\nStrong analytical skills in designing and implementing data solutions to address complex challenges from diverse stakeholders.",
      "4-5 years experience as a Data Engineer",
      "Experience working with cloud infrastructure such as Azure, AWS, or GCP.",
      "Experience working with data processing tools such as Apache Spark, Hadoop, Flink, Snowflake.",
      "Experience in SQL and Python",
      "Strong analytical skills in designing and implementing data solutions to address complex challenges from diverse stakeholders."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-hubble-pte-ltd-4546?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 261 Hoang Van Thu st, Tan Binh, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "English"
    ]
  },
  {
    "title": "Mid/Senior Data Analytics Engineer (HCL x ANZ Bank)",
    "company": "HCL Vietnam Company Limited",
    "salary_range": "1,500 - 2,496 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "India",
    "company_model": "Thuê ngoài",
    "company_size": "501-1000 nhân viên",
    "linh_vuc": "Thuê Ngoài Phát Triển Phần Mềm",
    "createdAt": " Đăng 9 ngày trước",
    "description": [
      "Mô tả công việc",
      "About the job",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "\n ",
      "",
      "JOB TITLE: Analytics Engineer (Mid level)",
      "JOB TITLE:",
      "JOB LOCATION: HCMC",
      "JOB LOCATION",
      "ABOUT HCL VIETNAM COMPANY LIMITED",
      "ABOUT HCL VIETNAM COMPANY LIMITED",
      "HCL Vietnam Company Limited belongs to HCLTech.",
      "HCLTech is a global technology company, home to more than 223,400 people across 60 countries,",
      "delivering industry-leading capabilities centered around digital, engineering, cloud, and AI, powered by a broad portfolio of technology services and products. We work with clients across all major verticals, providing industry solutions for Financial Services, Manufacturing, Life Sciences and Healthcare, Technology and Services, Telecom and Media, Retail and CPG, and Public Services. Consolidated revenues as of 12 months ending June 2023 totaled $12.8 billion. To learn how we can supercharge progress for you, visit",
      "Our Vietnam-based offices:",
      "Our Vietnam-based offices:",
      "Our Vietnam-based offices:",
      "• Hanoi Office: Level 13-17, Leadvisors Tower, 643 Pham Van Dong Street, Co Nhue Ward, North",
      "Tu Liem District, Hanoi",
      "• HCMC Office: Level 11, Five Star Tower, 28Bis Mac Dinh Chi Street, Da Kao Ward, District 1, HCMC\n ",
      "",
      "What is your mission?",
      "What is your mission?",
      "As an Analytics Engineer supporting the Data Enablement stream within ANZ Plus, your mission is to design and build the data products required to support operational pipelines as well as reporting, data science and analytics initiatives to drive business decision-making and innovative customer outcomes for the program.",
      "Your key accountability will be to build and maintain data products in our data mesh through engineering best practices using DBT, Python and BigQuery."
    ],
    "yc": [
      "Yêu cầu công việc",
      "What will your day look like:",
      "What will your day look like:",
      "What will your day look like:",
      "Understand user stories supporting a wide array of use cases such as reporting in Tableau, data science or analytics activities, or indeed operational data flows for decisioning and campaign tools \nDesign physical data structures in Google Big Query to optimise efficiency, scalability and consistency in a repeatable manner \nCatalogue and document metadata on available data sources and communicate rationale for modelling decisions made \nWork closely with the team to ensure data models align with stakeholder expectations and practical engineering patterns in DBT and Terraform \nProfile incoming source data (batch and real-time event) to deeply understand data, contribute to data integration specifications and help to build robust and future-proof models \nParticipate in the continuous improvement of data assets and governance processes to enable customers to easily access the data they need ",
      "Understand user stories supporting a wide array of use cases such as reporting in Tableau, data science or analytics activities, or indeed operational data flows for decisioning and campaign tools ",
      "Design physical data structures in Google Big Query to optimise efficiency, scalability and consistency in a repeatable manner ",
      "Catalogue and document metadata on available data sources and communicate rationale for modelling decisions made ",
      "Work closely with the team to ensure data models align with stakeholder expectations and practical engineering patterns in DBT and Terraform ",
      "Profile incoming source data (batch and real-time event) to deeply understand data, contribute to data integration specifications and help to build robust and future-proof models ",
      "Participate in the continuous improvement of data assets and governance processes to enable customers to easily access the data they need ",
      "What will you bring?",
      "What will you bring?",
      "What will you bring?",
      "To grow and be successful in this role, you will ideally bring the following:",
      "To grow and be successful in this role, you will ideally bring the following:",
      "From 4 years experience\nExcellent English communication skills \nExcellent SQL, data analysis and data profiling skills \nProven success designing and/or building BI/DW or ETL solutions, especially using data transformation tools such as DBT or Dataform \nDemonstrated experience with data pipeline orchestration and/or configuration as code \nExposure to data in cloud-native environments \nAn appreciation for difficult problems and to work autonomously on complex tasks \nThe Analytics Engineer role is a midpoint between Data Analyst and Data Engineer; you need to ‘care’ about the data itself, not just the pipelines, but also be comfortable with engineering practices such as source control, tagging, CI/CD and automated testing using Python. ",
      "From 4 years experience",
      "From 4 years experience",
      "Excellent English communication skills ",
      "Excellent English communication skills ",
      "Excellent SQL, data analysis and data profiling skills ",
      "Proven success designing and/or building BI/DW or ETL solutions, especially using data transformation tools such as DBT or Dataform ",
      "Demonstrated experience with data pipeline orchestration and/or configuration as code ",
      "Exposure to data in cloud-native environments ",
      "An appreciation for difficult problems and to work autonomously on complex tasks ",
      "The Analytics Engineer role is a midpoint between Data Analyst and Data Engineer; you need to ‘care’ about the data itself, not just the pipelines, but also be comfortable with engineering practices such as source control, tagging, CI/CD and automated testing using Python. ",
      "The Analytics Engineer role is a midpoint between Data Analyst and Data Engineer;",
      "At ANZ a growth mindset is at the heart of our culture and we actively encourage people to try new things. If this role interests you and you feel you have most of these things in your toolbox, we’d love to hear from you.",
      "At ANZ a growth mindset is at the heart of our culture and we actively encourage people to try new things. If this role interests you and you feel you have most of these things in your toolbox, we’d love to hear from you."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/mid-senior-data-analytics-engineer-hcl-x-anz-bank-hcl-vietnam-company-limited-0852?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Level 11, Five Star Tower, 28Bis Mac Dinh Chi Street, Da Kao Ward, District 1, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "Python",
      "SQL"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Global Fashion Group",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "United Kingdom",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "May mặc và Thời Trang",
    "createdAt": " Đăng 10 ngày trước",
    "description": [
      "Mô tả công việc",
      "Global Fashion Group is the leading fashion and lifestyle destination in growth markets across LATAM, SEA and ANZ. From our people to our customers and partners, we exist to empower everyone to express their true selves through fashion. Our three e-commerce platforms: Dafiti, ZALORA and THE ICONIC connect an assortment of international, local and own brands to over 800 million consumers from diverse cultures and lifestyles. GFG’s platforms provide seamless and inspiring customer experiences from discovery to delivery, powered by art & science that is infused with unparalleled local knowledge. As part of the Group’s vision is to be the #1 online destination for fashion & lifestyle in growth markets, we are committed to doing this responsibly by being people and planet positive across everything we do. ",
      " ",
      "ABOUT THE TEAM",
      "ABOUT THE TEAM",
      "At GFG, technology is core to long-term success and is a crucial enabler of a great customer experience. We are a mix of experts in fashion, logistics, data analytics, marketing and design, guided by business consultants and tech geniuses - everyone contributes to the success of GFG.",
      " ",
      "ABOUT THE ROLE ",
      "ABOUT THE ROLE ",
      "Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.\nWork in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.",
      "Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.",
      "Work in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.",
      "THE IMPACT YOU’LL MAKE ",
      "THE IMPACT YOU’LL MAKE ",
      "Data at GFG never stops growing and the team also never stops learning, innovating and expanding so that we can bring in or build the latest and best tools and technologies. In this role, you will be able to create strategic data models, develop and maintain data architecture used to power high-impact business initiatives that contribute to the overall growth and strategy for GFG."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Be familiar with:",
      "Be familiar with:",
      "Data structures & algorithms\nData modelling\nBasic machine learning algorithms\nFollowing languages: SQL, Python, R, Java/Scala\nAny of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift\nCloud technologies: AWS, GCP (BigQuery)",
      "Data structures & algorithms",
      "Data modelling",
      "Basic machine learning algorithms",
      "Following languages: SQL, Python, R, Java/Scala",
      "Any of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift",
      "Cloud technologies: AWS, GCP (BigQuery)",
      "2. Be knowledgeable in:",
      "2. Be knowledgeable in:",
      "Object oriented design and design patterns\nLarge-scale distributed systems\nHadoop, Spark and Pandas or similar processing engines\nJupyter Notebook or Zeppelin\nApache Airflow, Apache Superset",
      "Object oriented design and design patterns",
      "Large-scale distributed systems",
      "Hadoop, Spark and Pandas or similar processing engines",
      "Jupyter Notebook or Zeppelin",
      "Apache Airflow, Apache Superset",
      "3. Good to have:",
      "3. Good to have:",
      "Knowledge of data visualization\nGood background in statistics\nKnowledge in data analysis, data mining, or machine learning\nExperience working with big data",
      "Knowledge of data visualization",
      "Good background in statistics",
      "Knowledge in data analysis, data mining, or machine learning",
      "Experience working with big data"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-global-fashion-group-0305?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Copac Square Building, 12 Tôn Đản, phường 13, District 4, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "AWS"
    ]
  },
  {
    "title": "Senior Data Engineer (Python, SQL, Database)",
    "company": "DATAPOT",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 12 giờ trước",
    "description": [
      "Mô tả công việc",
      "About Datapot Analytics:",
      "About Datapot Analytics:",
      "Datapot Analytics is a leading data analytics group known for its cutting-edge solutions and innovative approach to data management. With a strong foundation in leveraging advanced analytics and AI technologies, Datapot Analytics has consistently delivered exceptional results for clients across various industries. Our mission is to empower businesses with actionable insights and drive data-driven decision-making.",
      "Datapot Analytics is a leading data analytics group known for its cutting-edge solutions and innovative approach to data management. With a strong foundation in leveraging advanced analytics and AI technologies, Datapot Analytics has consistently delivered exceptional results for clients across various industries. Our mission is to empower businesses with actionable insights and drive data-driven decision-making.",
      "Introducing KHantix:",
      "Introducing KHantix:",
      "Introducing KHantix:",
      "KHantix, a new venture under the Datapot Analytics umbrella, is set to revolutionize the data analytics landscape. Specializing in innovative solutions using Microsoft Data Analytics services, KHantix is dedicated to building a data-native company in the AI-first era. Our focus is on harnessing the power of data to create impactful solutions that drive business success",
      "KHantix, a new venture under the Datapot Analytics umbrella, is set to revolutionize the data analytics landscape. Specializing in innovative solutions using Microsoft Data Analytics services, KHantix is dedicated to building a data-native company in the AI-first era. Our focus is on harnessing the power of data to create impactful solutions that drive business success",
      "Job Description: Project Manager",
      "Job Description: ",
      "Job Description: ",
      "Project Manager",
      "Key Responsibilities:",
      "Key Responsibilities:",
      "Design, develop, and maintain scalable data pipelines and ETL processes to support data integration and analytics. \nImplement and optimize data storage solutions using Microsoft Fabric, Azure Synapse, Azure Data Factory, and other Microsoft data services. \nDevelop and maintain data models, databases, and data warehouses to ensure data accuracy and availability. \nEnsure data quality and integrity through rigorous testing and validation procedures. \nStay updated with the latest trends and best practices in data engineering and analytics. ",
      "Design, develop, and maintain scalable data pipelines and ETL processes to support data integration and analytics. ",
      "Implement and optimize data storage solutions using Microsoft Fabric, Azure Synapse, Azure Data Factory, and other Microsoft data services. ",
      "Develop and maintain data models, databases, and data warehouses to ensure data accuracy and availability. ",
      "Ensure data quality and integrity through rigorous testing and validation procedures. ",
      "Stay updated with the latest trends and best practices in data engineering and analytics. "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Qualifications:",
      "Qualifications:",
      "Bachelor’s or Master’s degree in Computer Science, Data, or a related field. \n5+ years of experience in data engineering, with a strong focus on Microsoft data analytics solutions. \nProficiency in SQL, Python, and other programming languages relevant to data engineering.\nStrong understanding of data modeling, ETL processes, and data warehousing concepts. \nExcellent problem-solving skills and attention to detail. ",
      "Bachelor’s or Master’s degree in Computer Science, Data, or a related field. ",
      "5+ years of experience in data engineering, with a strong focus on Microsoft data analytics solutions. ",
      "Proficiency in SQL, Python, and other programming languages relevant to data engineering.",
      "Strong understanding of data modeling, ETL processes, and data warehousing concepts. ",
      "Excellent problem-solving skills and attention to detail. ",
      "(*) Preferred Qualifications:",
      "(*) Preferred Qualifications:",
      "Experience with big data technologies such as Databricks, Hadoop and Spark. \nKnowledge of AI/ML techniques. \nFamiliarity with data governance and security best practices. ",
      "Experience with big data technologies such as Databricks, Hadoop and Spark. ",
      "Knowledge of AI/ML techniques. ",
      "Familiarity with data governance and security best practices. "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-sql-database-datapot-3746?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Tầng 9, toà nhà Gardenia, số 48 Bích Câu, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "Database",
      "SQL"
    ]
  },
  {
    "title": "Kỹ sư dữ liệu (Data Engineer/ Python/Java/ Database)",
    "company": "VNPT Net Corporation",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Viễn Thông",
    "createdAt": " Đăng 13 giờ trước",
    "description": [
      "Mô tả công việc",
      "Tham gia quy hoạch, thiết kế chi tiết, triển khai hạ tầng công nghệ và triển khai các ứng dụng CNTT/CĐS của VNPT Net trên hệ sinh thái dữ liệu lớn (Big Data) (Hadoop, Spark, Kafka, Zookeeper …) cũng như vận hành, quản trị các ứng dụng Big Data, đảm bảo yêu cầu về hiệu năng, tính dễ mở rộng, chất lượng dữ liệu, khả năng truy cập của các ứng dụng phân tích Big Data;\nPhối hợp với BA và Dev để chuyển đổi các yêu cầu người dùng thành các giải pháp công nghệ và tham gia xây dựng các ứng dụng trên nền tảng Big Data đã triển khai với các cấu trúc dữ liệu phức tạp, dung lượng lớn;\nNghiên cứu các xu hướng công nghệ Big Data mới, đánh giá tính phù hợp, khả thi và khả năng áp dụng tại môi trường VNPT Net để tăng hiệu quả công việc;\nTham mưu cho các cấp lãnh đạo về quy định, chính sách đầu tư triển khai, tích hợp nền tảng Big Data.",
      "Tham gia quy hoạch, thiết kế chi tiết, triển khai hạ tầng công nghệ và triển khai các ứng dụng CNTT/CĐS của VNPT Net trên hệ sinh thái dữ liệu lớn (Big Data) (Hadoop, Spark, Kafka, Zookeeper …) cũng như vận hành, quản trị các ứng dụng Big Data, đảm bảo yêu cầu về hiệu năng, tính dễ mở rộng, chất lượng dữ liệu, khả năng truy cập của các ứng dụng phân tích Big Data;",
      "Tham gia quy hoạch, thiết kế chi tiết, triển khai hạ tầng công nghệ và triển khai các ứng dụng CNTT/CĐS của VNPT Net trên hệ sinh thái dữ liệu lớn (Big Data) (Hadoop, Spark, Kafka, Zookeeper …) cũng như",
      "vận hành, quản trị các ứng dụng Big Data, đảm bảo yêu cầu về hiệu năng, tính dễ mở rộng, chất lượng dữ liệu, khả năng truy cập của các ứng dụng phân tích Big Data;",
      "Phối hợp với BA và Dev để chuyển đổi các yêu cầu người dùng thành các giải pháp công nghệ và tham gia xây dựng các ứng dụng trên nền tảng Big Data đã triển khai với các cấu trúc dữ liệu phức tạp, dung lượng lớn;",
      "Phối hợp với BA và Dev để chuyển đổi các yêu cầu người dùng thành các giải pháp công nghệ và tham gia xây dựng các ứng dụng trên nền tảng Big Data đã triển khai với các cấu trúc dữ liệu phức tạp, dung lượng lớn;",
      "Nghiên cứu các xu hướng công nghệ Big Data mới, đánh giá tính phù hợp, khả thi và khả năng áp dụng tại môi trường VNPT Net để tăng hiệu quả công việc;",
      "Nghiên cứu các xu hướng công nghệ Big Data mới, đánh giá tính phù hợp, khả thi và khả năng áp dụng tại môi trường VNPT Net để tăng hiệu quả công việc;",
      "Tham mưu cho các cấp lãnh đạo về quy định, chính sách đầu tư triển khai, tích hợp nền tảng Big Data.",
      "Tham mưu cho các cấp lãnh đạo về quy định, chính sách đầu tư triển khai, tích hợp nền tảng Big Data."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Độ tuổi:",
      "Độ tuổi:",
      "Độ tuổi:",
      "Tuyển dụng đối với các ứng viên không quá 27 tuổi. \nKhông quá 40 tuổi đối với các ứng viên có tối thiểu 05 năm gần nhất làm việc tại vị trí công việc tuyển dụng\nKhông giới hạn độ tuổi tuyển dụng đối với lao động CNTT đáp ứng ít nhất một trong các điều kiện sau: ",
      "Tuyển dụng đối với các ứng viên không quá 27 tuổi. ",
      "Tuyển dụng đối với các ứng viên không quá 27 tuổi. ",
      "Không quá 40 tuổi đối với các ứng viên có tối thiểu 05 năm gần nhất làm việc tại vị trí công việc tuyển dụng",
      "Không quá 40 tuổi đối với các ứng viên có tối thiểu 05 năm gần nhất làm việc tại vị trí công việc tuyển dụng",
      "Không giới hạn độ tuổi tuyển dụng đối với lao động CNTT đáp ứng ít nhất một trong các điều kiện sau: ",
      "Không giới hạn độ tuổi tuyển dụng đối với lao động CNTT đáp ứng ít nhất một trong các điều kiện sau: ",
      "+ Đã tham gia tối thiểu 03 dự án CNTT lớn triển khai cho các khách hàng là các tổ chức/doanh nghiệp uy tín trong và ngoài nước phù hợp với vị trí tuyển dụng. ",
      "+ Đã tham gia tối thiểu 03 dự án CNTT lớn triển khai cho các khách hàng là các tổ chức/doanh nghiệp uy tín trong và ngoài nước phù hợp với vị trí tuyển dụng. ",
      "+ Có các sản phẩm, công trình nghiên cứu trong lĩnh vực CNTT đạt giải thưởng của các tổ chức uy tín trong nước và quốc tế.",
      "+ Có các sản phẩm, công trình nghiên cứu trong lĩnh vực CNTT đạt giải thưởng của các tổ chức uy tín trong nước và quốc tế.",
      "Kỹ năng/chuyên môn nghiệp vụ:",
      "Kỹ năng/chuyên môn nghiệp vụ:",
      "Kỹ năng/chuyên môn nghiệp vụ:",
      "Bắt buộc:",
      "Bắt buộc:",
      "Bắt buộc:",
      "Ít nhất 1 năm kinh nghiệm nghiên cứu và phát triển BigData.\nThành thạo 1 trong các ngôn ngữ lập trình như Java, Scala, Python để triển khai các ứng dụng xử lý dữ liệu lớn.\nKiến thức về giám sát, lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn trong hệ sinh thái Hadoop bao gồm HDFS, MapReduce, YARN, HBase, Zookeeper, Pig, Hive ...\nCó kinh nghiệm trong việc xây dựng xử lý dữ liệu quy mô lớn (xử lý hàng loạt – batch processing, xử lý luồng - stream processing)\nKiển thức về các loại CSDL (RDBMS, Graph Databases, NoSQL Products, …).\nGiao tiếp tốt, quản lý công việc hiệu quả, có tinh thần trách nhiệm",
      "Ít nhất 1 năm kinh nghiệm nghiên cứu và phát triển BigData.",
      "Ít nhất 1 năm kinh nghiệm nghiên cứu và phát triển BigData.",
      "Thành thạo 1 trong các ngôn ngữ lập trình như Java, Scala, Python để triển khai các ứng dụng xử lý dữ liệu lớn.",
      "Thành thạo 1 trong các ngôn ngữ lập trình như Java, Scala, Python để triển khai các ứng dụng xử lý dữ liệu lớn.",
      "Kiến thức về giám sát, lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn trong hệ sinh thái Hadoop bao gồm HDFS, MapReduce, YARN, HBase, Zookeeper, Pig, Hive ...",
      "Kiến thức về giám sát, lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn trong hệ sinh thái Hadoop bao gồm HDFS, MapReduce, YARN, HBase, Zookeeper, Pig, Hive ...",
      "Có kinh nghiệm trong việc xây dựng xử lý dữ liệu quy mô lớn (xử lý hàng loạt – batch processing, xử lý luồng - stream processing)",
      "Có kinh nghiệm trong việc xây dựng xử lý dữ liệu quy mô lớn (xử lý hàng loạt – batch processing, xử lý luồng - stream processing)",
      "Kiển thức về các loại CSDL (RDBMS, Graph Databases, NoSQL Products, …).",
      "Kiển thức về các loại CSDL (RDBMS, Graph Databases, NoSQL Products, …).",
      "Giao tiếp tốt, quản lý công việc hiệu quả, có tinh thần trách nhiệm",
      "Giao tiếp tốt, quản lý công việc hiệu quả, có tinh thần trách nhiệm",
      "Ưu tiên",
      "Ưu tiên",
      "Ưu tiên",
      "Khả năng lập trình, tư duy tốt, tinh thần trách nhiệm và ý thức về chất lượng sản phẩm cao.\nKhả năng làm việc độc lập, tích cực, chủ động trong công việc, luôn luôn tìm tòi học hỏi những kiến thức và bài toán mới\nKhả năng làm việc nhóm tốt, nghiên cứu tốt với các tài liệu tiếng Anh.\nCó tinh thần chủ động học hỏi, đam mê với công nghệ mới",
      "Khả năng lập trình, tư duy tốt, tinh thần trách nhiệm và ý thức về chất lượng sản phẩm cao.",
      "Khả năng lập trình, tư duy tốt, tinh thần trách nhiệm và ý thức về chất lượng sản phẩm cao.",
      "Khả năng làm việc độc lập, tích cực, chủ động trong công việc, luôn luôn tìm tòi học hỏi những kiến thức và bài toán mới",
      "Khả năng làm việc độc lập, tích cực, chủ động trong công việc, luôn luôn tìm tòi học hỏi những kiến thức và bài toán mới",
      "Khả năng làm việc nhóm tốt, nghiên cứu tốt với các tài liệu tiếng Anh.",
      "Khả năng làm việc nhóm tốt, nghiên cứu tốt với các tài liệu tiếng Anh.",
      "Có tinh thần chủ động học hỏi, đam mê với công nghệ mới",
      "Có tinh thần chủ động học hỏi, đam mê với công nghệ mới",
      "Bằng cấp/ chuyên ngành đào tạo:",
      "Bằng cấp/ chuyên ngành đào tạo:",
      "Bằng cấp/ chuyên ngành đào tạo:",
      "Trình độ: Tốt nghiệp Đại học hệ chính quy; \nNhóm chuyên ngành CNTT hoặc Toán tin trong và ngoài nước. \nTiếng Anh: Nghe, nói, đọc hiểu tài liệu tiếng Anh (Ưu tiên có chứng chỉ tiếng Anh TOEIC 450 hoặc tương đương).\nHình thức đào tạo",
      "Trình độ: Tốt nghiệp Đại học hệ chính quy; ",
      "Trình độ: Tốt nghiệp Đại học hệ chính quy; ",
      "Nhóm chuyên ngành CNTT hoặc Toán tin trong và ngoài nước. ",
      "Nhóm chuyên ngành CNTT hoặc Toán tin trong và ngoài nước. ",
      "Tiếng Anh: Nghe, nói, đọc hiểu tài liệu tiếng Anh (Ưu tiên có chứng chỉ tiếng Anh TOEIC 450 hoặc tương đương).",
      "Tiếng Anh: Nghe, nói, đọc hiểu tài liệu tiếng Anh (Ưu tiên có chứng chỉ tiếng Anh TOEIC 450 hoặc tương đương).",
      "Hình thức đào tạo",
      "Hình thức đào tạo",
      "+ Lao động được đào tạo trong nước: Hệ chính quy; đối với những Bằng tốt nghiệp Đại học được cấp từ 01/7/2019 trở về sau không ghi hình thức đào tạo, hình thức đào tạo căn cứ trên Phụ lục của Bằng đại học. ",
      "+ Lao động được đào tạo trong nước: Hệ chính quy; đối với những Bằng tốt nghiệp Đại học được cấp từ 01/7/2019 trở về sau không ghi hình thức đào tạo, hình thức đào tạo căn cứ trên Phụ lục của Bằng đại học. ",
      "+ Lao động được đào tạo nước ngoài: Trình độ Đại học trở lên thuộc các trường có uy tín trên thế giới",
      "+ Lao động được đào tạo nước ngoài: Trình độ Đại học trở lên thuộc các trường có uy tín trên thế giới",
      "Kinh nghiệm công tác:",
      "Kinh nghiệm công tác:",
      "Kinh nghiệm công tác:",
      "Ưu tiên các ứng viên có kinh nghiệm làm việc trong lĩnh vực liên quan.",
      "Ưu tiên các ứng viên có kinh nghiệm làm việc trong lĩnh vực liên quan."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/ky-su-du-lieu-data-engineer-python-java-database-vnpt-net-corporation-1755?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Số 30 đường Phạm Hùng, phường Mỹ Đình 1, Nam Tu Liem, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Java",
      "Python",
      "Database"
    ]
  },
  {
    "title": "[DI6] Senior Data Engineer (SQL, Python) – MSB - 1Y565",
    "company": "MSB",
    "salary_range": "1,000 - 2,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 2 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.\nRà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.\nThường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.\nHỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.\nXây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.",
      "Rà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.",
      "Thường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.",
      "Hỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.",
      "Xây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin\nCó kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...\nCó kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL\nÍt nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)\nHiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới\nKhả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc\nKhả năng thiết kế Tích hợp dữ liệu thời gian thực",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin",
      "Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...",
      "Có kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL",
      "Ít nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)",
      " Java/Python/Scala, SQL",
      "Hiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới",
      "Khả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc",
      "Khả năng thiết kế Tích hợp dữ liệu thời gian thực"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/di6-senior-data-engineer-sql-python-msb-1y565-msb-0227?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " ROX Tower, 54A Nguyen Chi Thanh, phuong Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "Python",
      "Java"
    ]
  },
  {
    "title": "Data Engineer (Database/ Oracle / SQL)",
    "company": "MIC",
    "salary_range": "800 - 1,200 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Dịch Vụ Tài Chính",
    "createdAt": " Đăng 4 ngày trước",
    "description": [
      "Mô tả công việc",
      "Xây dựng và quản lý mô hình dữ liệu đảm bảo tuân thủ tiêu chuẩn kiến trúc dữ liệu.\nPhối hợp xây dựng và quản lý kiến trúc nguồn dữ liệu đối với các báo cáo và các cấu phần dữ liệu liên quan đến bảo mật dữ liệu và đáp ứng yêu cầu an ninh an toàn thông tin.\nĐầu mối thu thập dữ liệu từ các nguồn dữ liệu của MIC, phối hợp với các đơn vị khác trong vận hành, sao lưu, khôi phục, back up, bảo mật dữ liệu dữ liệu đáp ứng yêu cầu an ninh an toàn thông tin.\nĐầu mối thu thập, phân tích yêu cầu, thiết kế cơ sở dữ liệu cho các đơn vị nghiệp vụ (datamart), quản lý kiến trúc dữ liệu của hệ thống báo cáo.\nKiểm thử (SIT - System Integration Test) các giải pháp dữ liệu trên nền tảng dữ liệu.",
      "Xây dựng và quản lý mô hình dữ liệu đảm bảo tuân thủ tiêu chuẩn kiến trúc dữ liệu.",
      "Xây dựng và quản lý mô hình dữ liệu đảm bảo tuân thủ tiêu chuẩn kiến trúc dữ liệu.",
      "Phối hợp xây dựng và quản lý kiến trúc nguồn dữ liệu đối với các báo cáo và các cấu phần dữ liệu liên quan đến bảo mật dữ liệu và đáp ứng yêu cầu an ninh an toàn thông tin.",
      "Phối hợp xây dựng và quản lý kiến trúc nguồn dữ liệu đối với các báo cáo và các cấu phần dữ liệu liên quan đến bảo mật dữ liệu và đáp ứng yêu cầu an ninh an toàn thông tin",
      ".",
      "Đầu mối thu thập dữ liệu từ các nguồn dữ liệu của MIC, phối hợp với các đơn vị khác trong vận hành, sao lưu, khôi phục, back up, bảo mật dữ liệu dữ liệu đáp ứng yêu cầu an ninh an toàn thông tin.",
      "Đầu mối thu thập dữ liệu từ các nguồn dữ liệu của MIC, phối hợp với các đơn vị khác trong vận hành, sao lưu, khôi phục, back up, bảo mật dữ liệu dữ liệu đáp ứng yêu cầu an ninh an toàn thông tin.",
      "Đầu mối thu thập, phân tích yêu cầu, thiết kế cơ sở dữ liệu cho các đơn vị nghiệp vụ (datamart), quản lý kiến trúc dữ liệu của hệ thống báo cáo.",
      "Đầu mối thu thập, phân tích yêu cầu, thiết kế cơ sở dữ liệu cho các đơn vị nghiệp vụ (datamart), quản lý kiến trúc dữ liệu của hệ thống báo cáo.",
      "Kiểm thử (SIT - System Integration Test) các giải pháp dữ liệu trên nền tảng dữ liệu.",
      "Kiểm thử (SIT - System Integration Test) các giải pháp dữ liệu trên nền tảng dữ liệu."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học.\nCó từ 2 năm kinh nghiệm trong lập trình mảng DataBase (Dev, Core hệ thống, Bảng dữ liệu, Báo cáo).\nCó kinh nghiệm về DataBase Oracle, SQL Server , Reporting ( Oracle ODI, Oracle Gonden Gate,...)\nCó kinh nghiệm Thiết kế hệ thống DataBase và Tunning DataBase.\nƯu tiên ứng viên có kinh nghiệm về hệ thống bảo hiểm.",
      "Tốt nghiệp Đại học.",
      "Tốt nghiệp Đại học.",
      "Có từ 2 năm kinh nghiệm trong lập trình mảng DataBase (Dev, Core hệ thống, Bảng dữ liệu, Báo cáo).",
      "Có từ 2 năm kinh nghiệm trong lập trình mảng DataBase (Dev, Core hệ thống, Bảng dữ liệu, Báo cáo).",
      "Có kinh nghiệm về DataBase Oracle, SQL Server , Reporting ( Oracle ODI, Oracle Gonden Gate,...)",
      "Có kinh nghiệm về DataBase Oracle, SQL Server , Reporting ( Oracle ODI, Oracle Gonden Gate,...)",
      "Có kinh nghiệm Thiết kế hệ thống DataBase và Tunning DataBase.",
      "Có kinh nghiệm Thiết kế hệ thống DataBase và Tunning DataBase.",
      "Ưu tiên ứng viên có kinh nghiệm về hệ thống bảo hiểm.",
      "Ưu tiên ứng viên có kinh nghiệm về hệ thống bảo hiểm."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineer-database-oracle-sql-mic-2616?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Toà nhà MB, 21 Cát Linh, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Database",
      "SQL",
      "Oracle"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Picket Homes",
    "salary_range": "Start from $3000",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "United States",
    "company_model": "Sản phẩm",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Bất Động Sản và Xây Dựng",
    "createdAt": " Đăng 7 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are seeking an exceptional Senior Data Engineer to work closely with executives, real estate professionals, product managers, and engineers to develop and implement software solutions for managing listings and property data. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.  ",
      "We are seeking an exceptional Senior Data Engineer to work closely with executives, real estate professionals, product managers, and engineers to develop and implement software solutions for managing listings and property data. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.  "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Requirements",
      "Requirements",
      "3+ years of professional experience in data engineering and software development\nExpertise in Java or Kotlin\nProficiency in relational database\nUnderstanding of SW lifecycle including best practices in testing and deployment \nFamiliarity with Git, Linux, AWS, and other software tools and cloud services\nTechnical writing ability, including visual diagramming tools\nBachelor's degree from a top engineering university",
      "3+ years of professional experience in data engineering and software development",
      "Expertise in Java or Kotlin",
      "Proficiency in relational database",
      "Understanding of SW lifecycle including best practices in testing and deployment ",
      "Familiarity with Git, Linux, AWS, and other software tools and cloud services",
      "Technical writing ability, including visual diagramming tools",
      "Bachelor's degree from a top engineering university",
      "---",
      "Expectations",
      "Expectations",
      "Expectations",
      "In month one, complete company onboarding, and build your own development plan for ownership of an area in our data platform team.\nWithin the first three months, research and implement new features for our data ingestion services. Build out at least one new feature with another team member.\nWithin six months, create a roadmap for improving ingestion processes, documentation, and integration with other services, then begin executing it.",
      "In month one, complete company onboarding, and build your own development plan for ownership of an area in our data platform team.",
      "Within the first three months, research and implement new features for our data ingestion services. Build out at least one new feature with another team member.",
      "Within six months, create a roadmap for improving ingestion processes, documentation, and integration with other services, then begin executing it.",
      "Set your sights on the following by the end of your first year:",
      "Set your sights on the following by the end of your first year:",
      "Set your sights on the following by the end of your first year:",
      "Take ownership of ingestion services and continuously iterate to improve their reliability and robustness.  \nHelp build out the team through recruiting, high-bar interviewing, onboarding, and mentoring.\nGain a comprehensive understanding of real estate, housing, geographies, and market characteristics to enhance your decision-making and implementations. ",
      "Take ownership of ingestion services and continuously iterate to improve their reliability and robustness.  ",
      "Help build out the team through recruiting, high-bar interviewing, onboarding, and mentoring.",
      "Gain a comprehensive understanding of real estate, housing, geographies, and market characteristics to enhance your decision-making and implementations. ",
      " "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-picket-homes-1253?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 4th Floor, No 2 Alley 1 Lane 26 Do Quang Street Trung Hoa Ward, Cau Giay District Hanoi, Vietnam, Cau Giay, Ha Noi "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Java",
      "Kotlin",
      "Linux"
    ]
  },
  {
    "title": "Data Platform Engineer (Python/Java/Cloud)-K. Dữ Liệu",
    "company": "MB Bank",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Chưa có",
    "createdAt": " Đăng 13 ngày trước",
    "description": [
      "Mô tả công việc",
      "Xây dựng, phát triển và cung cấp giải pháp data platform với hiệu năng cao và chi phí thấp, end to end, hybrid onpremise & cloud native về lĩnh vực Big Data và ML phục vụ kinh doanh\nNghiên cứu, thử nghiệm, đánh giá, thiết kế, triển khai, kiểm thử, sử dụng, quản trị, vận hành, hỗ trợ, giám sát, bảo trì, nâng cấp, tối ưu data platform sử dụng công nghệ open source, chuẩn hóa quy trình và con người\nMở rộng các xu hướng công nghệ về ML và BigData trong lĩnh vực Ngân hàng phục vụ kinh doanh\nTham gia đề xuất, xây dựng giải pháp, cải tiến/xây mới và tham gia triển khai các dự án trong mảng chức năng được giao đảm bảo thực hiện thành công mục tiêu chung của đơn vị.\nTham gia review, đánh giá các giải pháp công nghệ của các đối tác liên quan đến lĩnh vực chuyên môn",
      "Xây dựng, phát triển và cung cấp giải pháp data platform với hiệu năng cao và chi phí thấp, end to end, hybrid onpremise & cloud native về lĩnh vực Big Data và ML phục vụ kinh doanh",
      "Xây dựng, phát triển và cung cấp giải pháp data platform với hiệu năng cao và chi phí thấp, end to end, hybrid onpremise & cloud native về lĩnh vực Big Data và ML phục vụ kinh doanh",
      "Nghiên cứu, thử nghiệm, đánh giá, thiết kế, triển khai, kiểm thử, sử dụng, quản trị, vận hành, hỗ trợ, giám sát, bảo trì, nâng cấp, tối ưu data platform sử dụng công nghệ open source, chuẩn hóa quy trình và con người",
      "Nghiên cứu, thử nghiệm, đánh giá, thiết kế, triển khai, kiểm thử, sử dụng, quản trị, vận hành, hỗ trợ, giám sát, bảo trì, nâng cấp, tối ưu data platform sử dụng công nghệ open source, chuẩn hóa quy trình và con người",
      "Mở rộng các xu hướng công nghệ về ML và BigData trong lĩnh vực Ngân hàng phục vụ kinh doanh",
      "Mở rộng các xu hướng công nghệ về ML và BigData trong lĩnh vực Ngân hàng phục vụ kinh doanh",
      "Tham gia đề xuất, xây dựng giải pháp, cải tiến/xây mới và tham gia triển khai các dự án trong mảng chức năng được giao đảm bảo thực hiện thành công mục tiêu chung của đơn vị.",
      "Tham gia đề xuất, xây dựng giải pháp, cải tiến/xây mới và tham gia triển khai các dự án trong mảng chức năng được giao đảm bảo thực hiện thành công mục tiêu chung của đơn vị.",
      "Tham gia review, đánh giá các giải pháp công nghệ của các đối tác liên quan đến lĩnh vực chuyên môn",
      "Tham gia review, đánh giá các giải pháp công nghệ của các đối tác liên quan đến lĩnh vực chuyên môn"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học các ngành công nghệ thông tin, công nghệ phần mềm, khoa học máy tính, hệ thống thống tin\nCó kinh nghiệm 01 năm làm Software Engineer, 01 năm kinh nghiệm ML/AI, 02 năm kinh nghiệm Data Engineer (big data) \nƯu tiên ứng viên có kinh nghiệm làm DP hoặc có định hướng làm DP\nƯu tiên các ứng viên từng làm Data Architect, Devsecops/ Dataops/ Mlops\nCó kiến thức vững về big data, data lake, data lakehouse, lambda architect, kappa architect, data fabric, distributed computing\nCó kinh nghiệm sử dụng open source, Spark, Flink, K8s, Python và Scala hoặc Java (trọng tâm)\nCó khả năng adapt đc với công nghệ mới, nghiên cứu và tìm hiểu, thích nghi nhanh với công nghệ mới\nYêu cầu có hiểu biết về các nền tảng hạ tầng & OS\nƯu tiên có kinh nghiệm làm cả onpremise và cả cloud (AWS or GCP or Azure)",
      "Tốt nghiệp Đại học các ngành công nghệ thông tin, công nghệ phần mềm, khoa học máy tính, hệ thống thống tin",
      "Tốt nghiệp Đại học các ngành công nghệ thông tin, công nghệ phần mềm, khoa học máy tính, hệ thống thống tin",
      "Có kinh nghiệm 01 năm làm Software Engineer, 01 năm kinh nghiệm ML/AI, 02 năm kinh nghiệm Data Engineer (big data) ",
      "Có kinh nghiệm 01 năm làm Software Engineer, 01 năm kinh nghiệm ML/AI, 02 năm kinh nghiệm Data Engineer (big data) ",
      "Ưu tiên ứng viên có kinh nghiệm làm DP hoặc có định hướng làm DP",
      "Ưu tiên ứng viên có kinh nghiệm làm DP hoặc có định hướng làm DP",
      "Ưu tiên các ứng viên từng làm Data Architect, Devsecops/ Dataops/ Mlops",
      "Ưu tiên các ứng viên từng làm Data Architect, Devsecops/ Dataops/ Mlops",
      "Có kiến thức vững về big data, data lake, data lakehouse, lambda architect, kappa architect, data fabric, distributed computing",
      "Có kiến thức vững về big data, data lake, data lakehouse, lambda architect, kappa architect, data fabric, distributed computing",
      "Có kinh nghiệm sử dụng open source, Spark, Flink, K8s, Python và Scala hoặc Java (trọng tâm)",
      "Có kinh nghiệm sử dụng open source, Spark, Flink, K8s, Python và Scala hoặc Java (trọng tâm)",
      "Có khả năng adapt đc với công nghệ mới, nghiên cứu và tìm hiểu, thích nghi nhanh với công nghệ mới",
      "Có khả năng adapt đc với công nghệ mới, nghiên cứu và tìm hiểu, thích nghi nhanh với công nghệ mới",
      "Yêu cầu có hiểu biết về các nền tảng hạ tầng & OS",
      "Yêu cầu có hiểu biết về các nền tảng hạ tầng & OS",
      "Ưu tiên có kinh nghiệm làm cả onpremise và cả cloud (AWS or GCP or Azure)",
      "Ưu tiên có kinh nghiệm làm cả onpremise và cả cloud (AWS or GCP or Azure)",
      " "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-platform-engineer-python-java-cloud-k-du-lieu-mb-bank-4101?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Tòa nhà MB, số 18 Lê Văn Lương, Cau Giay, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Java",
      "Python",
      "Cloud"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "NAB Innovation Centre Vietnam",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Australia",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 17 ngày trước",
    "description": [
      "Mô tả công việc",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      " ",
      "About the job:",
      "About the job:",
      "At NAB, we are at the forefront of building a next-generation Security Information and Event Management (SIEM) system. As part of this mission, we are seeking a dynamic and experienced engineers to join our newly formed SIEM Engineering team. This is a unique opportunity to be on the ground floor of a new capability, where you will play a crucial role in shaping the future of SIEM capabilities at NAB.",
      " ",
      "JOB RESPONSIBILITIES",
      "JOB RESPONSIBILITIES",
      "Use security best practices in the undertaking of their day-to-day responsibilities, \nIdentify and implement process improvements.\nActively identify, report, and implement risk remediation tasks as appropriate to your role. \nDesign, develop and implement solutions in collaboration with other technical teams.",
      "Use security best practices in the undertaking of their day-to-day responsibilities, ",
      "Identify and implement process improvements.",
      "Actively identify, report, and implement risk remediation tasks as appropriate to your role. ",
      "Design, develop and implement solutions in collaboration with other technical teams.",
      "You will:",
      "Engineer data supporting Cyber Security outcomes.\nExhibit and maintain high engineering standards, including documentation.\nContribute to setting the level of urgency within the team in addressing issues.\nHave a solid understanding of data processing and storage, alerting and searching techniques and technologies to guide and validate the work of your team\nAdhere to rigorous processes.",
      "Engineer data supporting Cyber Security outcomes.",
      "Exhibit and maintain high engineering standards, including documentation.",
      "Contribute to setting the level of urgency within the team in addressing issues.",
      "Have a solid understanding of data processing and storage, alerting and searching techniques and technologies to guide and validate the work of your team",
      "Adhere to rigorous processes."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tertiary qualification in a Technology discipline or related field\nQualifications and/or certifications in data, engineering and/or cybersecurity are highly valued.\n5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM\nExperience with a subset of the following technologies:\nAmazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)\nIdeally experience with Cyber Security domain.",
      "Tertiary qualification in a Technology discipline or related field",
      "Qualifications and/or certifications in data, engineering and/or cybersecurity are highly valued.",
      "5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM",
      "5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM",
      "Experience with a subset of the following technologies:\nAmazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)",
      "Amazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)",
      "Amazon SNS/SQS",
      "Azure Service Bus",
      "Azure Event Hubs",
      "Apache Kafka",
      "Windows Event Forwarder",
      "Syslog",
      "Cribl",
      "Splunk, including Data Modelling",
      "Data lake (eg, Snowflake or Data Bricks)",
      "Ideally experience with Cyber Security domain.",
      "Cyber Security domain."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-nab-innovation-centre-vietnam-4522?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " TNR Tower, 54A Nguyen Chi Thanh, Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Data Analyst",
      "Cloud",
      "Security"
    ]
  },
  {
    "title": "Data Engineer / Senior Data Engineer",
    "company": "Eyepax IT Consulting Company Limited",
    "salary_range": "1,000 - 2,250 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Singapore",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 19 ngày trước",
    "description": [
      "Mô tả công việc",
      "Eyepax is a global software solutions firm with a strong international presence spanning over 17 years. Headquartered in Singapore, we have development centers in Sri Lanka and Vietnam. As a member of our Vietnam team, you will join a workforce of over 180 IT professionals. ",
      "We seek a talented and motivated Data Engineer/Senior Data Engineer to join our development team. As a Data Engineer/Senior Data Engineer, you will play a key role in developing and maintaining the data infrastructure that supports our client’s operations. This is an excellent opportunity to contribute to the development and success of our organization. Proficiency in English communication is essential for seamless collaboration with teammates and clients worldwide."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Experience and Responsibilities:",
      "Experience and Responsibilities:",
      "Experience and Responsibilities:",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.\nA minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.\nDesign, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.\nCollaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).\nProficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).\nExperience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.\nSkilled in data analysis and able to interpret complex data sets and derive actionable insights.\nDefine and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.\nEnsure data quality, reliability, and security by supporting Data Governance processes.\nAble to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.\nKnowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.\nA basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.\nAssist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.",
      "A minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.",
      "A minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.",
      "Design, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.",
      "Design, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.",
      "Collaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).",
      "Collaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).",
      "Proficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).",
      "Proficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).",
      "Experience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.",
      "Experience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.",
      "Skilled in data analysis and able to interpret complex data sets and derive actionable insights.",
      "Skilled in data analysis and able to interpret complex data sets and derive actionable insights.",
      "Define and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.",
      "Define and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.",
      "Ensure data quality, reliability, and security by supporting Data Governance processes.",
      "Ensure data quality, reliability, and security by supporting Data Governance processes.",
      "Able to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.",
      "Able to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.",
      "Knowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.",
      "Knowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.",
      "A basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.",
      "A basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.",
      "Assist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Assist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Qualification and Personal Characteristics:",
      "Qualification and Personal Characteristics:",
      "Qualification and Personal Characteristics:",
      "Strong problem-solving and analytical skills with attention to detail.\nExcellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.\nAbility to learn new technologies quickly and innovate within the data space.\nStrong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.\nSelf-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes.",
      "Strong problem-solving and analytical skills with attention to detail.",
      "Strong problem-solving and analytical skills with attention to detail.",
      "Excellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.",
      "Excellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.",
      "Ability to learn new technologies quickly and innovate within the data space.",
      "Ability to learn new technologies quickly and innovate within the data space.",
      "Strong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.",
      "Strong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.",
      "Self-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes.",
      "Self-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/junior-senior-data-engineer-python-sql-aws-eyepax-it-consulting-company-limited-0402?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 2nd floor 15 Đ. Lê Thánh Tôn, Bến Nghé, District 1, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "Scala"
    ]
  },
  {
    "title": "Middle/Senior Data Engineer (Azure, Databricks)",
    "company": "TechSoft",
    "salary_range": "Negotiable",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 23 ngày trước",
    "description": [
      "Mô tả công việc",
      "Are you up to becoming a Data Engineer at TechSoft?",
      "a Data Engineer ",
      " ",
      "We are looking for a data engineer with a couple of years of experience. You hold a bachelor’s or master’s degree in computer science or equal through experience. You are part of a multidisciplinary scrum team that takes ownership of designing and implementing our platform and its software features, with a focus on data analytics. As a data engineer analyst, you’ll be building data pipelines and dataset quality monitoring to make raw data usable by stakeholders. ",
      " ",
      "You’ll have at least 5 years of experience working as a Data Engineer. On a personal level, you are passionate about data analytics and are always up to date in terms of new technology. You have a systematic approach in your way of working and are able to keep a sense of perspective of the different tasks. We expect you to have good communication skills and the ability to engage with many different people both internally in the organization and externally. You have excellent written and verbal communication skills in English.  ",
      " ",
      " ",
      "Key Responsibilities:",
      "Key Responsibilities",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features\nDesign, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. \nBuild the data foundations needed for a strong BI service to business and R&D stakeholders\nTransform our raw data into ready-to-use, high-quality datasets and build mechanisms to monitor their quality.\nSuggest, discuss, and define process improvements, and how can we improve our way of working ",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features",
      "Design, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. ",
      "Design, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. ",
      "Build the data foundations needed for a strong BI service to business and R&D stakeholders",
      "Transform our raw data into ready-to-use, high-quality datasets and build mechanisms to monitor their quality.",
      "Suggest, discuss, and define process improvements, and how can we improve our way of working "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Education: Bachelor's or Master's degree in Computer Science or related fields, or equivalent experience.\nExperience:\nAt least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence \nTechnical Skills:\nKnowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.\nPersonal Traits:\nExcellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Education: Bachelor's or Master's degree in Computer Science or related fields, or equivalent experience.",
      "Education",
      "Computer Science",
      "Experience:\nAt least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "Experience",
      "At least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "At least 5 years of experience working as a Data Engineer.",
      "5 years of experience",
      "Expertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.",
      "Expertise",
      "Databricks",
      "SQL",
      "Python",
      "Apache Spark",
      "PySpark",
      "orchestration tools, ",
      "and BI tools",
      "Experience with SCRUM teams and Agile methodology.",
      "SCRUM teams",
      "Agile methodology",
      "Experience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "Continuous Integration Principles",
      "Technical Skills:\nKnowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.",
      "Technical Skills",
      "Knowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.",
      "Knowledge of DevOps practices and tools like Docker, Kubernetes is a plus.",
      "DevOps practices",
      "Docker",
      "Kubernetes",
      "Certification in Azure Data Engineering or related areas is highly desirable.",
      "Certification",
      "Personal Traits:\nExcellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Personal Traits",
      "Excellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Excellent communication skills, both written and verbal, with fluency in English.",
      "communication skills",
      "English",
      "Self-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy ",
      "Self-responsibility ",
      "commitment",
      "Determination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-sql-database-techsoft-2436?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 45 Nguyễn Hữu An, Son Tra, Da Nang "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Cloud",
      "Azure",
      "Data Analyst"
    ]
  },
  {
    "title": "Data Engineer - Bonus 30,000,000 VND",
    "company": "FPT Software",
    "salary_range": "2,000 - 3,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Thêm lương OT",
    "nation": "Vietnam",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 24 ngày trước",
    "description": [
      "Mô tả công việc",
      "About us\nA subsidiary of the FPT Group, FPT Software is known as a leading global information technology service provider headquartered in Vietnam. With over 30,000 employees working in 83 offices across 30 countries on five continents, FPT Software consistently delivers the best solutions to more than 1000 clients, including 100 Fortune 500 companies. Placing human resources as the cornerstone of its achievements, employee experience is our top priority in continually creating an innovative, open, and enjoyable work environment for every member.",
      "About us",
      "",
      "In 2023, FPT Software officially made its mark on the global billion-dollar company list. This is evidence of the talent and efforts of multiple generations of employees at FPT Software.",
      "Why not explore your potential and embark on a brilliant journey with us?",
      " ",
      "Job Brief",
      "Job Brief",
      "• We are seeking a talented and motivated Data Engineer to join our team. As a Data Engineer, you will play a vital role in designing, building, and maintaining data pipelines to enable seamless data integration and analysis. The ideal candidate should have a strong foundation in data engineering concepts, excellent Python programming skills, experience with Apache Airflow for workflow automation, and proficiency in Google Cloud Platform (GCP) services like Google Cloud Storage (GCS), BigQuery, and Dataproc.",
      "Data Engineer",
      " ",
      "Job Overview",
      "Job Overview",
      "• Design and develop data pipelines to ingest, transform, and load data within GCP.",
      "• Collaborate with cross-functional teams to understand data requirements and implement scalable data solutions.",
      "• Implement data quality checks and data governance measures to ensure data accuracy and reliability.",
      "• Optimize data processing and performance to meet the organization’s data processing needs.",
      "• Troubleshoot data pipeline issues and work on performance optimization.",
      " ",
      "Responsibilities",
      "Responsibilities",
      "• Develop and maintain data pipelines using Apache Airflow and our custom tools.",
      "• Collaborate stakeholders to understand data needs.",
      "• Implement data transformations and data enrichment processes.",
      "Schedule, monitor, and troubleshoot data workflows using Airflow and our custom tools.",
      "• Work with GCP services like GCS, BigQuery and Dataproc to process and analyze data efficiently.",
      "• Create and maintain documentation for data pipelines and processes."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Must-Have:",
      "Must-Have:",
      "• Bachelor’s degree in Computer Science, Data Science, or a related field.",
      "• Having 3.5+ year of experience as a data engineer.",
      "• Strong understanding of data engineering principles and concepts.",
      "• Proficiency in Python programming for data manipulation and transformation.",
      "• Hands-on experience with Apache Airflow.",
      "• Familiarity with Google Cloud Platform (GCP) services such as GCS, BigQuery, and Dataproc.",
      "• Strong foundation knowledge of SQL and database systems.",
      "• Solid problem-solving and analytical skills to identify and resolve data pipeline issues.",
      " ",
      "Soft and Communication Skills:",
      "Soft and Communication Skills:",
      "• Good English skills (Listening, Speaking, Reading, Writing)",
      "• Highly motivated, eager to learn, and adaptable to new technologies and challenges.",
      "• Excellent communication and teamwork skills to collaborate with various stakeholders."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineer-bonus-30-000-000-vnd-fpt-software-5531?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " FPT Cau Giay Building, Cau Giay, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Database",
      "Python",
      "SQL"
    ]
  },
  {
    "title": "Middle - Senior Data Engineer (Azure, Databricks)",
    "company": "EMESOFT",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Thuê ngoài",
    "company_size": "1-50 nhân viên",
    "linh_vuc": "Thuê Ngoài Phát Triển Phần Mềm",
    "createdAt": " Đăng 24 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are looking for a skilled Data Engineer with expertise in Python, Pytest, and Databricks. This role involves designing, developing, and maintaining data processing systems and pipelines, utilizing Python’s full capabilities and Databricks’ cloud-based analytics platform. ",
      "Data Engineer",
      "Python",
      "Pytest",
      "Databricks",
      "The position requires a deep understanding of data engineering principles and the ability to apply them effectively in a dynamic environment.",
      "RESPONSIBILITIES",
      "RESPONSIBILITIES",
      "Cooperate with the infrastructure team to design, develop, and maintain the customers’ data platform.\nBuild data pipelines to extract, transform, and load data from a variety of sources\nBuild data warehouses and data lakes to store and manage data\nDevelop and deploy data processing and analytics tools\nWork with the infrastructure team to build data warehouse or data lake to support customers for data driven decisions.\nStay up-to-date on the latest data technologies",
      "Cooperate with the infrastructure team to design, develop, and maintain the customers’ data platform.",
      "Build data pipelines to extract, transform, and load data from a variety of sources",
      "Build data warehouses and data lakes to store and manage data",
      "Develop and deploy data processing and analytics tools",
      "Work with the infrastructure team to build data warehouse or data lake to support customers for data driven decisions.",
      "Stay up-to-date on the latest data technologies"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Bachelor’s degree in computer science, data science, or a related field.\nMinimum of 3 years of hands-on experience in data engineering, demonstrating practical proficiency.\nStrong understanding of data engineering principles and practices, with a focus on real-world application.\nProven experience with a variety of data technologies, including Databricks and Azure Data Factory (ADF), AWS Glue or similar cloud services\nProficiency in SQL and excellent programming skills in Python (pandas, polars, pyspark) or Scala, including unit testing with tools like pytest.\nExperience with cloud computing platforms such as Azure/AWS/GCP, with preference given to candidates holding relevant cloud data certifications (Azure Data Engineer Associate, AWS Certified Data Engineer, Google Professional Data Engineer)..\nFamiliarity with big data technologies, such as Hadoop, Spark, and Hive, is highly desirable.\nExperience with data visualization tools like PowerBI or Tableau is a plus.\nDemonstrated ability to learn and apply new technologies in a hands-on manner quickly.\nCapacity to work both independently and collaboratively within a team, showcasing strong problem-solving skills and initiative.",
      "Bachelor’s degree in computer science, data science, or a related field.",
      "Minimum of 3 years of hands-on experience in data engineering, demonstrating practical proficiency.",
      "hands-on",
      "Strong understanding of data engineering principles and practices, with a focus on real-world application.",
      "Proven experience with a variety of data technologies, including Databricks and Azure Data Factory (ADF), AWS Glue or similar cloud services",
      "Databricks",
      "Azure Data Factory (ADF)",
      "Proficiency in SQL and excellent programming skills in Python (pandas, polars, pyspark) or Scala, including unit testing with tools like pytest.",
      "Experience with cloud computing platforms such as Azure/AWS/GCP, with preference given to candidates holding relevant cloud data certifications (Azure Data Engineer Associate, AWS Certified Data Engineer, Google Professional Data Engineer)..",
      "Familiarity with big data technologies, such as Hadoop, Spark, and Hive, is highly desirable.",
      "Experience with data visualization tools like PowerBI or Tableau is a plus.",
      "PowerBI",
      "Tableau",
      "Demonstrated ability to learn and apply new technologies in a hands-on manner quickly.",
      "Capacity to work both independently and collaboratively within a team, showcasing strong problem-solving skills and initiative."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/mid-sr-data-engineer-python-sql-azure-databricks-emesoft-2141?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Floor 8, 596 Cong Hoa, Ward 13, Tan Binh, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "SQL",
      "Azure"
    ]
  },
  {
    "title": "Senior Data Engineer (Python, Data Warehouse, Alert)",
    "company": "Simple Tech Investment",
    "salary_range": "1,800 - 2,500 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "301-500 nhân viên",
    "linh_vuc": "Dịch Vụ Tài Chính",
    "createdAt": " Đăng 31 ngày trước",
    "description": [
      "Mô tả công việc",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.\nClarify requirements with Developers and Business users to build a data mart that meets functional/non-functional business requirements.\nDesign and maintain optimal data pipeline architecture.\nSupport internal training and proper documentation ensuring the successful onboarding of new team members.\nImplement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nDevelop efficient software code for multiple use cases leveraging Spark and Big Data Technologies for various use cases built on the platform.",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.",
      "Build the infrastructure",
      "required",
      "Clarify requirements with Developers and Business users to build a data mart that meets functional/non-functional business requirements.",
      "Clarify requirements",
      "build a data mart",
      "Design and maintain optimal data pipeline architecture.",
      "Design and maintain optimal data pipeline",
      "Support internal training and proper documentation ensuring the successful onboarding of new team members.",
      "Support internal",
      "Implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.",
      "Implement internal process improvements",
      "Develop efficient software code for multiple use cases leveraging Spark and Big Data Technologies for various use cases built on the platform.",
      "Develop efficient software code"
    ],
    "yc": [
      "Yêu cầu công việc",
      " At least 4+ years’ experience working as a Senior Data Engineer role, ETL with large amounts of data. Bachelor’s degree in related technical discipline.\nExperience with data warehousing architecture, Data modeling and ETL data pipeline. \nExperience in monitoring data quality, code factor, Data quality control alert, ...\nExperience with using the following software/tool in the big data field.\nNoSQL and OLAP database: MongoDB, Elastic search, etc.\nGood at programming languages: Scala, Python, Java.\nExperience in the data testing process.\nExperience in performing root cause analysis, identify problems and propose recommendations for improvement.\nStrong organizational and multitasking skills with the ability to balance competing priorities.\nFundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP).",
      " At least 4+ years’ experience working as a Senior Data Engineer role, ETL with large amounts of data. Bachelor’s degree in related technical discipline.",
      "+ years’ experience ",
      " of data. Bachelor’s degree ",
      ".",
      "Experience with data warehousing architecture, Data modeling and ETL data pipeline. ",
      "Experience with data warehousing architecture, Data modeling",
      "Experience in monitoring data quality, code factor, Data quality control alert, ...",
      "Experience with using the following software/tool in the big data field.",
      "Experience with using the following software/tool in the big data field.",
      "NoSQL and OLAP database: MongoDB, Elastic search, etc.",
      "Good at programming languages: Scala, Python, Java.",
      "Good at ",
      " Scala, Python, Java.",
      "Experience in the data testing process.",
      "Experience in the data testing process.",
      "Experience in performing root cause analysis, identify problems and propose recommendations for improvement.",
      "Experience in performing root cause analysis, identify problems and propose recommendations for improvement.",
      "Strong organizational and multitasking skills with the ability to balance competing priorities.",
      "Strong organizational and multitasking skills ",
      ".",
      "Fundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP).",
      "Fundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP)."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-data-warehouse-alert-simple-tech-investment-1826?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 402 Nguyễn Thị Minh Khai, District 3, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "Database",
      "NoSQL"
    ]
  },
  {
    "title": "Data Engineer - Hybrid working (Oracle, P/L SQL, T SQL)",
    "company": "SHBFinance",
    "salary_range": "1,300 - 1,500 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Dịch Vụ Tài Chính",
    "createdAt": " Đăng 8 ngày trước",
    "description": [
      "Mô tả công việc",
      "MỤC TIÊU CÔNG VIỆC: ",
      "MỤC TIÊU CÔNG VIỆC: ",
      "Đảm bảo việc phối hợp với với các phòng ban liên quan triển khai và tham gia phát triển/triển khai các dự án về dữ liệu, khai thác dữ liệu cũng như các công việc khác theo phân công của Trưởng phòng/ Trưởng bộ phận.\nĐảm bảo việc vận hành ứng dụng trên hệ thống Data Warehouse, Data mart và các hệ thống giá trị gia tăng ổn định phù hợp với chiến lược kinh doanh, chiến lược công nghệ.",
      "Đảm bảo việc phối hợp với với các phòng ban liên quan triển khai và tham gia phát triển/triển khai các dự án về dữ liệu, khai thác dữ liệu cũng như các công việc khác theo phân công của Trưởng phòng/ Trưởng bộ phận.",
      "Đảm bảo việc vận hành ứng dụng trên hệ thống Data Warehouse, Data mart và các hệ thống giá trị gia tăng ổn định phù hợp với chiến lược kinh doanh, chiến lược công nghệ.",
      "NHIỆM VỤ, TRÁCH NHIỆM CHÍNH:",
      "NHIỆM VỤ, TRÁCH NHIỆM CHÍNH:",
      "Đánh giá, xây dựng các mô hình kiến trúc hệ thống dữ liệu của công ty; Phân tích thiết kế và phát triển các hệ thống dữ liệu của Công ty.\nQuản lý các giải pháp lưu trữ dữ liệu của công ty như: DWH, Datalake, Datamart để tìm ra các vấn đề về hiệu suất và đưa ra giải pháp tối ưu hóa hiệu suất.\nThiết kế luồng ETL dữ liệu từ các nguồn dữ liệu trong công ty như: LMS, LOS, CRM, CSS,… về các hệ thống kho dữ liệu tập trung (DWH, Datalake, Datamart,…).\nĐề xuất, tham mưu với TBP các giải pháp công nghệ khả dụng, các giải pháp, kiến trúc mới phù hợp với đặc thù công việc của công ty.\nTổ chức triển khai áp dụng các giải pháp công nghệ phù hợp nhu cầu công việc.\nPhối hợp, hỗ trợ các bộ phận/ phòng ban khác trong công ty để cung cấp giải pháp dữ liệu và hỗ trợ lấy dữ liệu.\nXác định, đề xuất và triển khai các giải pháp sáng tạo để giảm chi phí hoặc tăng hiệu suất/hiệu quả công việc.\nĐánh giá cải thiện hạ tầng và quy trình dữ liệu để phù hợp với nhu cầu phát triển của công ty.\nĐề xuất, triển khai các giải pháp nhằm kiểm soát, giảm thiểu số lượng lỗi; nâng cao chất lượng sản phẩm sau khi bàn giao sang vận hành và mức độ hài lòng của người dùng nội bộ và đối tác về hoạt động và sản phẩm của Khối Công Nghệ.\nThực hiện các công việc khác theo yêu cầu của cấp quản lý.",
      "Đánh giá, xây dựng các mô hình kiến trúc hệ thống dữ liệu của công ty; Phân tích thiết kế và phát triển các hệ thống dữ liệu của Công ty.",
      "Quản lý các giải pháp lưu trữ dữ liệu của công ty như: DWH, Datalake, Datamart để tìm ra các vấn đề về hiệu suất và đưa ra giải pháp tối ưu hóa hiệu suất.",
      "Thiết kế luồng ETL dữ liệu từ các nguồn dữ liệu trong công ty như: LMS, LOS, CRM, CSS,… về các hệ thống kho dữ liệu tập trung (DWH, Datalake, Datamart,…).",
      "Đề xuất, tham mưu với TBP các giải pháp công nghệ khả dụng, các giải pháp, kiến trúc mới phù hợp với đặc thù công việc của công ty.",
      "Tổ chức triển khai áp dụng các giải pháp công nghệ phù hợp nhu cầu công việc.",
      "Phối hợp, hỗ trợ các bộ phận/ phòng ban khác trong công ty để cung cấp giải pháp dữ liệu và hỗ trợ lấy dữ liệu.",
      "Xác định, đề xuất và triển khai các giải pháp sáng tạo để giảm chi phí hoặc tăng hiệu suất/hiệu quả công việc.",
      "Đánh giá cải thiện hạ tầng và quy trình dữ liệu để phù hợp với nhu cầu phát triển của công ty.",
      "Đề xuất, triển khai các giải pháp nhằm kiểm soát, giảm thiểu số lượng lỗi; nâng cao chất lượng sản phẩm sau khi bàn giao sang vận hành và mức độ hài lòng của người dùng nội bộ và đối tác về hoạt động và sản phẩm của Khối Công Nghệ.",
      "Thực hiện các công việc khác theo yêu cầu của cấp quản lý."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học chuyên ngành Công nghệ thông tin, Toán Tin ứng dụng hoặc các chuyên ngành tương tự.\nCó ít nhất 3 năm trong lĩnh vực phát triển dữ liệu, báo cáo và phát triển phần mềm của ngành tài chính ngân hàng.\nHiểu biết về các quy trình phát triển phần mềm; Các công cụ quản trị dự án, môi trường phát triển ứng dụng, ngôn ngữ lập trình ứng dụng, cơ sở dữ liệu.\nHiểu biết về một số mảng nghiệp vụ ngân hàng, phần mềm ứng dụng trong ngân hàng - tài chính.\nToeic > 405 \nThành thạo về các hệ quản trị cơ sở dữ liệu, Data warehouse, Big data trong lĩnh vực tài chính, ngân hàng, hệ thống Core Banking và Cơ sở dữ liệu quy mô lớn.\nCó tư duy lập trình tốt, sử dụng thành thạo một trong các ứng dụng cơ sở dữ liệu như: Oracle, My SQL, Postgre,…\nKinh nghiệm lập trình ứng dụng về DWH, công cụ tích hợp, ETL tool, Các công cụ phát triển báo cáo.\nHiểu biết các phần mềm báo cáo và tính toán, phân tích số liệu.kiến trúc, dữ liệu của các hệ thống của Bộ phận Phát triển Dịch vụ và Nền tảng dữ liệu.\nKhả năng tư duy logic.\nKhả năng nghiên cứu/ học hỏi để làm việc hiệu quả.\nKhả năng lập kế hoạch và tổ chức.\nKỹ năng giải quyết vấn đề.",
      "Tốt nghiệp Đại học chuyên ngành Công nghệ thông tin, Toán Tin ứng dụng hoặc các chuyên ngành tương tự.",
      "Có ít nhất 3 năm trong lĩnh vực phát triển dữ liệu, báo cáo và phát triển phần mềm của ngành tài chính ngân hàng.",
      "Có ít nhất 3 năm trong lĩnh vực phát triển dữ liệu, báo cáo và phát triển phần mềm của ngành tài chính ngân hàng.",
      "Hiểu biết về các quy trình phát triển phần mềm; Các công cụ quản trị dự án, môi trường phát triển ứng dụng, ngôn ngữ lập trình ứng dụng, cơ sở dữ liệu.",
      "Hiểu biết về một số mảng nghiệp vụ ngân hàng, phần mềm ứng dụng trong ngân hàng - tài chính.",
      "Toeic > 405 ",
      "Thành thạo về các hệ quản trị cơ sở dữ liệu, Data warehouse, Big data trong lĩnh vực tài chính, ngân hàng, hệ thống Core Banking và Cơ sở dữ liệu quy mô lớn.",
      "hành thạo về các hệ quản trị cơ sở dữ liệu, Data warehouse, Big data trong lĩnh vực tài chính, ngân hàng, hệ thống Core Banking và Cơ sở dữ liệu quy mô lớn.",
      "Có tư duy lập trình tốt, sử dụng thành thạo một trong các ứng dụng cơ sở dữ liệu như: Oracle, My SQL, Postgre,…",
      "Kinh nghiệm lập trình ứng dụng về DWH, công cụ tích hợp, ETL tool, Các công cụ phát triển báo cáo.",
      "Kinh nghiệm lập trình ứng dụng về DWH, công cụ tích hợp, ETL tool, Các công cụ phát triển báo cáo.",
      "Hiểu biết các phần mềm báo cáo và tính toán, phân tích số liệu.kiến trúc, dữ liệu của các hệ thống của Bộ phận Phát triển Dịch vụ và Nền tảng dữ liệu.",
      "Khả năng tư duy logic.",
      "Khả năng nghiên cứu/ học hỏi để làm việc hiệu quả.",
      "Khả năng lập kế hoạch và tổ chức.",
      "Kỹ năng giải quyết vấn đề."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineer-hybrid-working-oracle-p-l-sql-t-sql-shbfinance-1721?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Gelex Tower, 52 Lê Đại Hành, phường Lê Đại Hành, Hai Ba Trung, Ha Noi "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Database",
      "SQL",
      "Oracle"
    ]
  },
  {
    "title": "Data Engineering (Python, SQL, Oracle)",
    "company": "HDBank",
    "salary_range": "1,200 - 1,500 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 12 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are seeking a skilled and passionate data to join our Data team. The successful candidate will play a crucial role in designing, building, and managing our data systems, providing valuable insights to support strategic decision-making and drive business growth.",
      "Responsibilities:",
      "Responsibilities:",
      "Collaborate with the Data team to gather, collect, and synthesize data from various systems into the data warehouse\nDesign and implement data warehouse, data mart, and data dictionary architectures to meet business needs\nAnalyze data from multiple sources using advanced statistical and extract meaningful insights.\nDevelop and maintain comprehensive KPI reports to track business performance and inform decision-making.\nDevelop SBV reports\nPartner with stakeholders across various departments, including business, sales, marketing, and IT, to gather requirements and communicate analysis results\nShare data analysis knowledge and expertise with team members and conduct training sessions",
      "Collaborate with the Data team to gather, collect, and synthesize data from various systems into the data warehouse",
      "Design and implement data warehouse, data mart, and data dictionary architectures to meet business needs",
      "Analyze data from multiple sources using advanced statistical and extract meaningful insights.",
      "Develop and maintain comprehensive KPI reports to track business performance and inform decision-making.",
      "Develop SBV reports",
      "Partner with stakeholders across various departments, including business, sales, marketing, and IT, to gather requirements and communicate analysis results",
      "Share data analysis knowledge and expertise with team members and conduct training sessions"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Skills:",
      "Skills:",
      "2+ years of experience in data engineering, data operation, with a proven track record of success in large-scale and complex projects\nProficiency in data analysis programming languages such as PL/SQL, SQL, Python\nExperience working with big data tools and platforms like Oracle, PostgreSQL, Spark.\nIn-depth knowledge of statistics, machine learning, and advanced data analysis techniques\nGood at written and verbal communication skills\nStrong collaboration and teamwork abilities\nCreative problem-solving and critical thinking skills\nAbility to learn quickly and adapt to new environments",
      "2+ years of experience in data engineering, data operation, with a proven track record of success in large-scale and complex projects",
      "Proficiency in data analysis programming languages such as PL/SQL, SQL, Python",
      "Experience working with big data tools and platforms like Oracle, PostgreSQL, Spark.",
      "In-depth knowledge of statistics, machine learning, and advanced data analysis techniques",
      "Good at written and verbal communication skills",
      "Strong collaboration and teamwork abilities",
      "Creative problem-solving and critical thinking skills",
      "Ability to learn quickly and adapt to new environments",
      "Knowledge:",
      "Knowledge:",
      "Domain expertise in the finance, banking\nUnderstanding of emerging data analysis trends and technologies\nBachelor's degree in Computer Science, University Of Science, or a related field",
      "Domain expertise in the finance, banking",
      "Understanding of emerging data analysis trends and technologies",
      "Bachelor's degree in Computer Science, University Of Science, or a related field",
      "Bonus:",
      "Bonus:",
      "Experience with cloud platforms like AWS and Azure\nFamiliarity with Power BI\nUnderstanding of financial concepts and banking products",
      "Experience with cloud platforms like AWS and Azure",
      "Familiarity with Power BI",
      "Understanding of financial concepts and banking products"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineering-python-sql-oracle-hdbank-1825?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 25 Nguyễn Thị Minh Khai, District 1, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "SQL",
      "Oracle"
    ]
  },
  {
    "title": "Kỹ Sư Dữ Liệu (Data Engineer, SQL)",
    "company": "Ngân hàng TMCP Thịnh vượng và Phát triển (PGBank)",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 21 ngày trước",
    "description": [
      "Mô tả công việc",
      "Mục đích Công việc:",
      "Mục đích Công việc:",
      "Chịu trách nhiệm vận hành luồng dữ liệu;",
      "Chịu trách nhiệm vận hành luồng dữ liệu;",
      "Chịu trách nhiệm vận hành luồng dữ liệu;",
      "Nhiệm vụ chính:",
      "Nhiệm vụ chính:",
      "Vận hành luồng dữ liệu:\nThực hiện đồng bộ dữ liệu từ các nguồn theo tài liệu đặc tả kỹ thuật, tài liệu phân tích kỹ thuật;\nThực hiện xử lý, tổng hợp dữ liệu ở mức độ nâng cao;\nVận hành các job ETL dữ liệu;\nThiết lập các vùng lưu trữ dữ liệu theo yêu cầu đặc tả của đơn vị nghiệp vụ;\nĐóng gói, triển khai dữ liệu cho môi trường UAT, Production; \nPhát triển các báo cáo quản trị\nThực hiện các nhiệm vụ khác theo phân công của cấp quản lý.",
      "Vận hành luồng dữ liệu:",
      "Thực hiện đồng bộ dữ liệu từ các nguồn theo tài liệu đặc tả kỹ thuật, tài liệu phân tích kỹ thuật;",
      "Thực hiện xử lý, tổng hợp dữ liệu ở mức độ nâng cao;",
      "Vận hành các job ETL dữ liệu;",
      "Thiết lập các vùng lưu trữ dữ liệu theo yêu cầu đặc tả của đơn vị nghiệp vụ;",
      "Đóng gói, triển khai dữ liệu cho môi trường UAT, Production; ",
      "Phát triển các báo cáo quản trị",
      "Thực hiện các nhiệm vụ khác theo phân công của cấp quản lý."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Yêu cầu: ",
      "Yêu cầu: ",
      "Tốt nghiệp đại học trở lên các chuyên ngành phù hợp như CNTT/Điện tử viễn thông hoặc các chuyên ngành có liên quan đến CNTT;\nƯu tiên có kinh nghiệm làm việc trong lĩnh vực tài chính - ngân hàng;\nThành thạo ngôn ngữ SQL và các ngôn ngữ truy vấn dữ liệu khác; \nCó khả năng sử dụng ít nhất một công cụ : ",
      "Tốt nghiệp đại học trở lên các chuyên ngành phù hợp như CNTT/Điện tử viễn thông hoặc các chuyên ngành có liên quan đến CNTT;",
      "Ưu tiên có kinh nghiệm làm việc trong lĩnh vực tài chính - ngân hàng;",
      "Ưu tiên có kinh nghiệm làm việc trong lĩnh vực tài chính - ngân hàng;",
      "Thành thạo ngôn ngữ SQL và các ngôn ngữ truy vấn dữ liệu khác; \nCó khả năng sử dụng ít nhất một công cụ : ",
      "Thành thạo ngôn ngữ SQL và các ngôn ngữ truy vấn dữ liệu khác; ",
      "",
      "Có khả năng sử dụng ít nhất một công cụ : ",
      "Có khả năng sử dụng ít nhất một công cụ : ",
      "           Confluent",
      "           Confluent",
      "           MinIO",
      "           MinIO",
      "           Kafka",
      "           Kafka",
      "           Iceberg",
      "           Iceberg",
      "           Dremio",
      "Hiểu biết và có khả năng sử dụng công cụ trực quan hóa dữ liệu hoặc ngôn ngữ phân tích dữ liệu\nKỹ năng Tiếng Anh đọc hiểu dữ liệu.",
      "Hiểu biết và có khả năng sử dụng công cụ trực quan hóa dữ liệu hoặc ngôn ngữ phân tích dữ liệu",
      "Hiểu biết và có khả năng sử dụng công cụ trực quan hóa dữ liệu hoặc ngôn ngữ phân tích dữ liệu",
      "Kỹ năng Tiếng Anh đọc hiểu dữ liệu.",
      "Kỹ năng Tiếng Anh đọc hiểu dữ liệu."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/ky-su-du-lieu-data-engineer-sql-ngan-hang-tmcp-thinh-vuong-va-phat-trien-pgbank-0206?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 229 Tây Sơn, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Database",
      "SQL",
      "English"
    ]
  },
  {
    "title": "Data Engineer (Bash script, Linux OS)",
    "company": "Officience",
    "salary_range": "Up to 650$",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "France",
    "company_model": "Thuê ngoài",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 22 ngày trước",
    "description": [
      "Mô tả công việc",
      "Be a member of a dedicated team\nProgram new scripts to crawl new sites, new strategies to overcome technical difficulties (IP blocked, encrypted data,..)\nKeep on optimizing crawling process\nDesign and implement a web app about real estate\nCommunicate with clients on innovations or improvements.\nResearch machine learning model, visualize data (language, number)\nOther works according to project requirements",
      "Be a member of a dedicated team",
      "Program new scripts to crawl new sites, new strategies to overcome technical difficulties (IP blocked, encrypted data,..)",
      "Keep on optimizing crawling process",
      "Design and implement a web app about real estate",
      "Communicate with clients on innovations or improvements.",
      "Research machine learning model, visualize data (language, number)",
      "Other works according to project requirements"
    ],
    "yc": [
      "Yêu cầu công việc",
      "At least 1+ years using Linux OS, Bash script.\nFamiliar with Crawling Data from the website is mandatory.\nKnowledge about web technology.\nExperienced in SQL, and MySQL databases.\nExperienced in Bash scripting, Python.\nExperienced in Docker, Jenkin, Nodejs (current frameworks being used include puppeteer, playwright).\nTeamwork spirit, responsibility, and good English.\nHaving knowledge or experience in Machine Learning Operations (MLOps) is a PLUS.\nData mining or have an interest in Data Science.",
      "At least 1+ years using Linux OS, Bash script.",
      "At least 1+ years using Linux OS, Bash script.",
      "Familiar with Crawling Data from the website is mandatory.",
      "Crawling Data",
      "Knowledge about web technology.",
      "Experienced in SQL, and MySQL databases.",
      " SQL, and MySQL",
      "Experienced in Bash scripting, Python.",
      "Bash scripting, Python.",
      "Experienced in Docker, Jenkin, Nodejs (current frameworks being used include puppeteer, playwright).",
      "Experienced in Docker, Jenkin, Nodejs (current frameworks being used include puppeteer, playwright).",
      "Teamwork spirit, responsibility, and good English.",
      "Teamwork spirit, responsibility, and good English.",
      "Having knowledge or experience in Machine Learning Operations (MLOps) is a PLUS.",
      "(MLOps) ",
      "Data mining or have an interest in Data Science.",
      "Data mining or have an interest in Data Science."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineer-bash-script-linux-os-officience-0054?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " F-Central, 16A Le Hong Phong, ward 12, District 10, Ho Chi Minh ",
      " Chấp nhận Fresher"
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Linux",
      "SQL"
    ]
  },
  {
    "title": "[DI6] Senior Data Engineer (SQL, Python) – MSB - 1Y565",
    "company": "MSB",
    "salary_range": "1,000 - 2,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 23 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.\nRà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.\nThường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.\nHỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.\nXây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.",
      "Rà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.",
      "Thường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.",
      "Hỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.",
      "Xây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin\nCó kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...\nCó kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL\nÍt nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)\nHiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới\nKhả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc\nKhả năng thiết kế Tích hợp dữ liệu thời gian thực",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin",
      "Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...",
      "Có kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL",
      "Ít nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)",
      " Java/Python/Scala, SQL",
      "Hiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới",
      "Khả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc",
      "Khả năng thiết kế Tích hợp dữ liệu thời gian thực"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/di6-senior-data-engineer-sql-python-msb-1y565-msb-4254?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " ROX Tower, 54A Nguyen Chi Thanh, phuong Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "Python",
      "Java"
    ]
  },
  {
    "title": "Quản trị Hạ tầng CSDL (DBA/ Data Engineer, SQL)",
    "company": "VietinBank",
    "salary_range": "Very attractive!!!",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 42 ngày trước",
    "description": [
      "Mô tả công việc",
      "Quản trị CSDL, chịu trách nhiệm cài đặt, cấu hình, nâng cấp, quản trị, giám sát, bảo trì và bảo mật cơ sở dữ liệu Rdbms, Nosql trong trong datacenter hoặc trên cloud. \nGiám sát, xử lý kịp thời các sự cố cơ sở dữ liệu.\nThiết kế triển khai các giải pháp bảo mật bảo vệ dữ liệu. Thực hiện patching các bản vá bảo mật CSDL\nTunning các hệ thống CSDL, tối ưu hóa hiệu năng hệ thống. Đưa ra khuyến cáo về các câu lệnh chưa tối ưu và khuyến cáo phương án xử lý cho bộ phận phát triển ứng dụng\nQuản lý vòng đời dữ liệu, tối ưu về lưu trữ dữ liệu và đảm bảo khai thác được dữ liệu hiệu quả nhất.\nXây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (Big Data)\nXây dựng các giải pháp ETL có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhau\nXây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu\nTham gia triển khai các dự án CNTT theo sự phân công của lãnh đạo",
      "Quản trị CSDL, chịu trách nhiệm cài đặt, cấu hình, nâng cấp, quản trị, giám sát, bảo trì và bảo mật cơ sở dữ liệu Rdbms, Nosql trong trong datacenter hoặc trên cloud. ",
      "Giám sát, xử lý kịp thời các sự cố cơ sở dữ liệu.",
      "Thiết kế triển khai các giải pháp bảo mật bảo vệ dữ liệu. Thực hiện patching các bản vá bảo mật CSDL",
      "Tunning các hệ thống CSDL, tối ưu hóa hiệu năng hệ thống. Đưa ra khuyến cáo về các câu lệnh chưa tối ưu và khuyến cáo phương án xử lý cho bộ phận phát triển ứng dụng",
      "Quản lý vòng đời dữ liệu, tối ưu về lưu trữ dữ liệu và đảm bảo khai thác được dữ liệu hiệu quả nhất.",
      "Xây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (Big Data)",
      "Xây dựng các giải pháp ETL có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhau",
      "Xây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu",
      "Tham gia triển khai các dự án CNTT theo sự phân công của lãnh đạo"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Trình độ:",
      "Trình độ:",
      "Như YC chung",
      "Kinh nghiệm:",
      "Kinh nghiệm:",
      "Thành thạo ít nhất một hệ quản trị CSDL như oracle, postgresql, mongodb..., thành thạo ngôn ngữ truy vấn SQL.\nHiểu biết về HĐH Linux",
      "Thành thạo ít nhất một hệ quản trị CSDL như oracle, postgresql, mongodb..., thành thạo ngôn ngữ truy vấn SQL.",
      "Hiểu biết về HĐH Linux",
      "* Đặc biệt ưu tiên các ứng viên: ",
      "Có chứng chỉ bảo mật an ninh mạng\nCó kinh nghiệm về lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Cloudera, Spark, Elastic Search...)\nCó chứng chỉ về quản trị CSDL như của AWS, Oracle,...",
      "Có chứng chỉ bảo mật an ninh mạng",
      "Có kinh nghiệm về lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Cloudera, Spark, Elastic Search...)",
      "Có chứng chỉ về quản trị CSDL như của AWS, Oracle,...",
      "Yêu cầu Kĩ năng mềm",
      "Yêu cầu Kĩ năng mềm",
      "Chủ động, sáng tạo trong công việc, có ý thức kỷ luật cao,\nChịu được áp lực công việc và tinh thần trách nhiệm cao\nCó kỹ năng làm việc nhóm. \nCó khả năng nghiên cứu công nghệ mới và tích hợp hệ thống.",
      "Chủ động, sáng tạo trong công việc, có ý thức kỷ luật cao,",
      "Chịu được áp lực công việc và tinh thần trách nhiệm cao",
      "Có kỹ năng làm việc nhóm. ",
      "Có khả năng nghiên cứu công nghệ mới và tích hợp hệ thống."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/quan-tri-ha-tang-csdl-dba-data-engineer-sql-vietinbank-1600?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 187 Nguyễn Lương Bằng , Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "AWS",
      "Data Analyst"
    ]
  },
  {
    "title": "Senior Data Engineer (Onprem/Signing Bonus 0.5 Month)",
    "company": "Giao Hàng Tiết Kiệm",
    "salary_range": "2,500 - 3,000 USD",
    "timeWork": "Thứ 2 - Thứ 7",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Vận Tải, Logistics và Kho Hàng",
    "createdAt": " Đăng 44 ngày trước",
    "description": [
      "Mô tả công việc",
      "– Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ big data: Hadoop\necosystem, kafka, spark, …;\n– Nghiên cứu và triển khai các công nghệ lưu trữ và tính toán trên hệ thống bigdata;\n– Vận hành, triển khai các job ETL, tổng hợp dữ liệu;\n– Xây dựng & triển khai hệ thống phát hiện bất thường, hệ thống Hồ sơ khách hàng đảm bảo hiệu năng và tính sẵn sàng cao;\n– Làm việc với các team khác: Vận hành, Sản phẩm, BA.",
      "– Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ big data: Hadoop",
      "",
      "ecosystem, kafka, spark, …;",
      "",
      "– Nghiên cứu và triển khai các công nghệ lưu trữ và tính toán trên hệ thống bigdata;",
      "",
      "– Vận hành, triển khai các job ETL, tổng hợp dữ liệu;",
      "",
      "– Xây dựng & triển khai hệ thống phát hiện bất thường, hệ thống Hồ sơ khách hàng đảm bảo hiệu năng và tính sẵn sàng cao;",
      "",
      "– Làm việc với các team khác: Vận hành, Sản phẩm, BA."
    ],
    "yc": [
      "Yêu cầu công việc",
      "– Có khả năng lập trình chuyên sâu java/python/scala;\n– Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, BI, sử dụng các mã nguồn mở như Hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;\n– Lập trình thông thạo spark, spark-streaming;\n– Có kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc\nLambda/Kappa/Data Lake;\n– Có kinh nghiệm xây dựng các hệ thống customer 360 đảm bảo hiệu năng và tính sẵn sàng cao;\n– Tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.",
      "– Có khả năng lập trình chuyên sâu java/python/scala;",
      "",
      "– Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, BI, sử dụng các mã nguồn mở như Hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;",
      "",
      "– Lập trình thông thạo spark, spark-streaming;",
      "",
      "– Có kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc",
      "",
      "Lambda/Kappa/Data Lake;",
      "",
      "– Có kinh nghiệm xây dựng các hệ thống customer 360 đảm bảo hiệu năng và tính sẵn sàng cao;",
      "",
      "– Tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-onprem-signing-bonus-0-5-month-giao-hang-tiet-kiem-4951?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " GHTK Building, đường Phạm Hùng, phường Mễ Trì, quận Nam Từ Liêm, thành phố Hà Nội, Nam Tu Liem, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Java",
      "Python",
      "MySQL"
    ]
  },
  {
    "title": "Data Engineering/Ops (1 year contract)",
    "company": "Ngân Hàng Á Châu | ACB",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 23 ngày trước",
    "description": [
      "Mô tả công việc",
      "Dự án Data Platform Design Project là chương trình Data Platform (Hệ thống nền tảng dữ liệu) thiết kế toàn bộ giải pháp về dữ liệu lớn. Mục tiêu chính của dự án là đưa ra kiến trúc Data Platform hoàn chỉnh nhằm cung cấp và truyền tải dữ liệu realtime phục vụ cho nhu cầu kinh doanh của toàn hàng.",
      "Data Platform Design Project",
      "Nhu cầu tuyển mới nhân sự ngành Data ở 2 lĩnh vực sau:\n1/ DataOps Engineer",
      "",
      "2/ Data Engineer",
      " ",
      "MÔ TẢ CÔNG VIỆC",
      "MÔ TẢ CÔNG VIỆC",
      "Hợp đồng ký kết 1 năm theo tiến độ dự án.",
      "Hợp đồng ký kết 1 năm theo tiến độ dự án.",
      "Tham gia cùng đối tác thiết kế/ đánh giá mô hình kiến trúc tổng quan/ triển khai thỏa mãn các yêu cầu để triển khai trên toàn bộ hệ thống của ACB.\nHiểu rõ từng thành phần trong kiến trúc Data platform.\nLựa chọn công nghệ triển khai từng giai đoạn/ thành phần trong Data platform. (Có trình bày nguyên nhân lựa chọn, so sánh đánh giá ưu/ nhược từng loại).\nThử nghiệm các công nghệ/ giải pháp lựa chọn trong quá trình thiết kế làm cơ sở cho báo cáo đánh giá kết quả hoàn thành dự án. \nTổ chức triển khai công việc phát triển các thành phần trong Data platform.",
      "Tham gia cùng đối tác thiết kế/ đánh giá mô hình kiến trúc tổng quan/ triển khai thỏa mãn các yêu cầu để triển khai trên toàn bộ hệ thống của ACB.",
      "Hiểu rõ từng thành phần trong kiến trúc Data platform.",
      "Lựa chọn công nghệ triển khai từng giai đoạn/ thành phần trong Data platform. (Có trình bày nguyên nhân lựa chọn, so sánh đánh giá ưu/ nhược từng loại).",
      "Thử nghiệm các công nghệ/ giải pháp lựa chọn trong quá trình thiết kế làm cơ sở cho báo cáo đánh giá kết quả hoàn thành dự án. ",
      "Tổ chức triển khai công việc phát triển các thành phần trong Data platform."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp đại học trở lên các chuyên nghành: CNTT/ Data Management/ Information System hoặc các chuyên ngành tương đương\nÍt nhất 1 năm kinh nghiệm ở vị trí DataOps Engineer/ Data Engineer\nCó kinh nghiệm với cơ sở dữ liệu SQL và NoSQL databases\nHiểu biết các công cụ big data như: Hadoop, Spark, Kafka, v.v\nCó kinh nghiệm với các công cụ quản lý luồng dữ liệu và quy trình làm việc như: Airflow, etc.\nCó kiến thức về Google Cloud Service là một lợi thế\nCó khả năng tự học, nghiên cứu các công nghệ mới ứng dụng vào công việc\nCó tinh thần trách nhiệm cao, nhiệt tình trong công việc\nKỹ năng quan sát, lắng nghe và phân tích nhu cầu dự án\nHam học hỏi, cầu tiến trong công việc.",
      "Tốt nghiệp đại học trở lên các chuyên nghành: CNTT/ Data Management/ Information System hoặc các chuyên ngành tương đương",
      "Ít nhất 1 năm kinh nghiệm ở vị trí DataOps Engineer/ Data Engineer",
      "Có kinh nghiệm với cơ sở dữ liệu SQL và NoSQL databases",
      "Hiểu biết các công cụ big data như: Hadoop, Spark, Kafka, v.v",
      "Có kinh nghiệm với các công cụ quản lý luồng dữ liệu và quy trình làm việc như: Airflow, etc.",
      "Có kiến thức về Google Cloud Service là một lợi thế",
      "Có khả năng tự học, nghiên cứu các công nghệ mới ứng dụng vào công việc",
      "Có tinh thần trách nhiệm cao, nhiệt tình trong công việc",
      "Kỹ năng quan sát, lắng nghe và phân tích nhu cầu dự án",
      "Ham học hỏi, cầu tiến trong công việc."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-engineering-ops-1-year-contract-ngan-hang-a-chau-acb-0021?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 444 CMT8, Ward 11, District 3, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "NoSQL"
    ]
  },
  {
    "title": "Data Scientist (Big Data, Python, SQL, Data Enginner)",
    "company": "VietinBank",
    "salary_range": "Very attractive!!!",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 1 ngày trước",
    "description": [
      "Mô tả công việc",
      "Làm một trong các mảng công việc sau:",
      "Data Scientist",
      "Data Scientist",
      "Phối hợp với nghiệp vụ phân tích vấn đề kinh doanh, phân tích khám phá (EDA), mô hình hóa dữ liệu để tìm ra xu hướng kinh doanh, hình mẫu, bản chất của hiện tượng, hành vi người dùng,…và đưa ra các nhận định trong việc ứng dụng khai thác dữ liệu vào hoạt động kinh doanh tạo ra giá trị. Tư vấn cho nghiệp vụ, đội ngũ BA/DA về hướng triển khai ứng dụng học máy, học sâu vào hoạt động kinh doanh.\nXây dựng mô hình học máy giải quyết các bài toàn phát triển kinh doanh.\nXây dựng luồng ETL tổng hợp dữ liệu, tiền xử lý, trích xuất đặc trưng với định dạng phù hợp với mục đích xây dựng từng loại mô hình.\nNghiên cứu công cụ, giải pháp, thuật toán nhằm xây dựng mô hình học máy, học sâu trên quy mô dữ liệu lớn với Pyspark, Tensorflow/Pytorch,… ứng dụng triển khai các chương trình kinh doanh, marketing, ứng dụng xây dựng hệ thống khuyến nghị, tích hợp gia tăng hiệu quả app/web…\nNghiên cứu thiết kế, cài đặt, tối ưu các thuật toán, công nghệ học máy, học sâu triển khai hiệu quả các bài toán.",
      "Phối hợp với nghiệp vụ phân tích vấn đề kinh doanh, phân tích khám phá (EDA), mô hình hóa dữ liệu để tìm ra xu hướng kinh doanh, hình mẫu, bản chất của hiện tượng, hành vi người dùng,…và đưa ra các nhận định trong việc ứng dụng khai thác dữ liệu vào hoạt động kinh doanh tạo ra giá trị. Tư vấn cho nghiệp vụ, đội ngũ BA/DA về hướng triển khai ứng dụng học máy, học sâu vào hoạt động kinh doanh.",
      "Xây dựng mô hình học máy giải quyết các bài toàn phát triển kinh doanh.",
      "Xây dựng luồng ETL tổng hợp dữ liệu, tiền xử lý, trích xuất đặc trưng với định dạng phù hợp với mục đích xây dựng từng loại mô hình.",
      "Nghiên cứu công cụ, giải pháp, thuật toán nhằm xây dựng mô hình học máy, học sâu trên quy mô dữ liệu lớn với Pyspark, Tensorflow/Pytorch,… ứng dụng triển khai các chương trình kinh doanh, marketing, ứng dụng xây dựng hệ thống khuyến nghị, tích hợp gia tăng hiệu quả app/web…",
      "Nghiên cứu thiết kế, cài đặt, tối ưu các thuật toán, công nghệ học máy, học sâu triển khai hiệu quả các bài toán."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp ĐH trở lên chuyên ngành: Khoa học dữ liệu, Khoa học máy tính, CNTT, Toán học ứng dụng, hoặc chuyên ngành khác liên quan;\nThành thạo các ngôn ngữ truy vấn CSDL như SQL và NoSQL . \nKiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, ElasticSearch, Kafka, …)\nKiến thức xây dựng, tối ưu luồng xử lý dữ liệu (batch processing, stream procesing, …);\nCó chứng chỉ quốc tế về Data Enginner (AWS, CCA, CCP, IBM Certified Data Engineer, Google Professional Data Engineer …) là một lợi thế",
      "Tốt nghiệp ĐH trở lên chuyên ngành: Khoa học dữ liệu, Khoa học máy tính, CNTT, Toán học ứng dụng, hoặc chuyên ngành khác liên quan;",
      "Thành thạo các ngôn ngữ truy vấn CSDL như SQL và NoSQL . ",
      "SQL ",
      "NoSQL ",
      "Kiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, ElasticSearch, Kafka, …)",
      "Hadoop, Spark, ElasticSearch, Kafka, …",
      "Kiến thức xây dựng, tối ưu luồng xử lý dữ liệu (batch processing, stream procesing, …);",
      "Có chứng chỉ quốc tế về Data Enginner (AWS, CCA, CCP, IBM Certified Data Engineer, Google Professional Data Engineer …) là một lợi thế",
      "Data Enginner",
      "Hoặc có các kiến thức sau",
      "Kiến thức về xác suất thống kê, đại số tuyến tính, lập trình, cấu trúc dữ liệu & giải thuật, lý thuyết đồ thị, cơ sở dữ liệu, mô hình học máy decision trees, linear regression, ensemble (random forest, boosting tree), k-means, SVM, PCA…;\nKiến thức về phân tích khám phá dữ liệu (Exploratory Data Analysis - EDA);\nKỹ năng sử dụng thành thạo một trong các package học máy (scikit-learn, TensorFlow, Keras, PyTorch, Pyspark MLlib, …);\nKỹ năng sử dụng ngôn ngữ lập trình (Python, Java, Scala, R, …), SQL, các thư viện Pandas, Numpy\nKỹ năng sử dụng các công cụ trực quan hóa dữ liệu, đánh giá mô hình.\nCó kiến thức về học sâu, mạng neural nhân tạo, các kiểu mạng MLP, CNN, LSTM, RNN là một lợi thế\nCó kiến thức về xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, …) là một lợi thế;",
      "Kiến thức về xác suất thống kê, đại số tuyến tính, lập trình, cấu trúc dữ liệu & giải thuật, lý thuyết đồ thị, cơ sở dữ liệu, mô hình học máy decision trees, linear regression, ensemble (random forest, boosting tree), k-means, SVM, PCA…;",
      "Kiến thức về phân tích khám phá dữ liệu (Exploratory Data Analysis - EDA);",
      "Kỹ năng sử dụng thành thạo một trong các package học máy (scikit-learn, TensorFlow, Keras, PyTorch, Pyspark MLlib, …);",
      "Kỹ năng sử dụng ngôn ngữ lập trình (Python, Java, Scala, R, …), SQL, các thư viện Pandas, Numpy",
      "(Python, Java, Scala, R, …), SQL",
      "Kỹ năng sử dụng các công cụ trực quan hóa dữ liệu, đánh giá mô hình.",
      "Có kiến thức về học sâu, mạng neural nhân tạo, các kiểu mạng MLP, CNN, LSTM, RNN là một lợi thế",
      "Có kiến thức về xử lý dữ liệu phân tán, xử lý dữ liệu lớn (Hadoop, Spark, …) là một lợi thế;"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/data-scientist-big-data-python-sql-data-enginner-vietinbank-1052?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 187 Nguyễn Lương Bằng , Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "SQL",
      "Data Analyst"
    ]
  },
  {
    "title": "Senior Officer, Business Itelligence",
    "company": "Techcombank",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 8 ngày trước",
    "description": [
      "Mô tả công việc",
      "Job Purpose",
      "Job Purpose",
      "The job holder analyzes, designs and implements data solutions using Techcombank’s enterprise suite of BI tools. \nThe job holder uses analysis, business understanding methods, processes, and systems to consolidate and analyse, visualize data to generate insights to inform and trigger business problems in the business decision process- improve of customer value and operation efficiency. \nThe job holder helps the business to better understand the implications of what information means, identifies what has happened, why it happened, especially for performance management",
      "The job holder analyzes, designs and implements data solutions using Techcombank’s enterprise suite of BI tools. ",
      "The job holder uses analysis, business understanding methods, processes, and systems to consolidate and analyse, visualize data to generate insights to inform and trigger business problems in the business decision process- improve of customer value and operation efficiency. ",
      "The job holder helps the business to better understand the implications of what information means, identifies what has happened, why it happened, especially for performance management",
      "Key Accountabilities (1)\nAnalysis and Reporting",
      "Key Accountabilities (1)",
      "",
      "Identify, analyze and interpret trends or patterns in complex data sets using script languages.\nPerform analysis of datasets to develop metrics, reports and visualizations mostly for performance management.\nUse data visualization programs, tools and techniques to generate dashboards, reports and presentations that aid in data storytelling, understanding and interpretation of trends and patterns of business importance to provide meanings to data produce.\nCreate and maintain statistical models for ongoing and ad hoc review and analysis of data.\nUnderstand data requirements from within and outside of the Data và Analytics Division and analyze needs of the business while assisting senior Data và Analytics Division members to develop the required technical requirements.\nCommunicate and align with stakeholders on purpose and impact of analytical solutions on business.\nContribute to the development and maintenance of Data và Analytics Division’s know-how.",
      "Identify, analyze and interpret trends or patterns in complex data sets using script languages.",
      "Perform analysis of datasets to develop metrics, reports and visualizations mostly for performance management.",
      "Use data visualization programs, tools and techniques to generate dashboards, reports and presentations that aid in data storytelling, understanding and interpretation of trends and patterns of business importance to provide meanings to data produce.",
      "Create and maintain statistical models for ongoing and ad hoc review and analysis of data.",
      "Understand data requirements from within and outside of the Data và Analytics Division and analyze needs of the business while assisting senior Data và Analytics Division members to develop the required technical requirements.",
      "Communicate and align with stakeholders on purpose and impact of analytical solutions on business.",
      "Contribute to the development and maintenance of Data và Analytics Division’s know-how.",
      "Key Accountabilities (2)\nData Insighting",
      "Key Accountabilities (2)",
      "",
      "Lead the identification and interpretation of meaningful and actionable insights from various data sources.\nDevelop processes and tools to monitor and analyze model performance and data accuracy. Interact with squads within assigned Data và Analytics Division to identify questions and issues for data analysis.\nAssess the effectiveness and accuracy of new data sources and data gathering techniques. \nMentor a team of BI analysts to deliver data solutions for a Data và Analytics Division.",
      "Lead the identification and interpretation of meaningful and actionable insights from various data sources.",
      "Develop processes and tools to monitor and analyze model performance and data accuracy. Interact with squads within assigned Data và Analytics Division to identify questions and issues for data analysis.",
      "Assess the effectiveness and accuracy of new data sources and data gathering techniques. ",
      "Mentor a team of BI analysts to deliver data solutions for a Data và Analytics Division.",
      "Key Relationships - Direct Manager ",
      "Key Relationships ",
      "Director, Business Intelligence ",
      "Key Relationships - Internal Stakeholders ",
      "Key Relationships",
      "Members of Business and Data & Analytics Division, Enabling Data & Analytics Division (IT or Data - Engineer/Governance), BAU division heads (Business, Finance, Risk, Corporate Affair, IT) ",
      "Key Relationships - External Stakeholders ",
      "Key Relationships ",
      "Partners and vendors providing professional services",
      " Success Profile -Qualification and Experiences"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Bachelor's degree in Finance, Risk Management, Statistics, Mathematics or Quantitative Analysis \nWork Experience 3+ years of relevant experience in areas of data analysis, reporting and planning, problem solving for business \nEnglish proficiency requirements are pursuant to Techcombank's policy \nExperience in querying databases and using programming languages (e.g. R, Python, Scala, SQL) \nExperience in building reporting with actionable intelligent \nExperience communicating complex analysis and models across a diverse team \nExperience in data management, ETL and analysis functions \nExperience with data analysis and BI tools such as Tableau, QlikView, Spark would be a plus \nDeep understanding of Information Security principles to ensure compliant handling and management of data \nStrong understanding of Agile principles, practices and scrum methodology \nExperience working in Agile teams to support digital transformation projects",
      "Bachelor's degree in Finance, Risk Management, Statistics, Mathematics or Quantitative Analysis ",
      "Work Experience 3+ years of relevant experience in areas of data analysis, reporting and planning, problem solving for business ",
      "English proficiency requirements are pursuant to Techcombank's policy ",
      "Experience in querying databases and using programming languages (e.g. R, Python, Scala, SQL) ",
      "Experience in building reporting with actionable intelligent ",
      "Experience communicating complex analysis and models across a diverse team ",
      "Experience in data management, ETL and analysis functions ",
      "Experience with data analysis and BI tools such as Tableau, QlikView, Spark would be a plus ",
      "Deep understanding of Information Security principles to ensure compliant handling and management of data ",
      "Strong understanding of Agile principles, practices and scrum methodology ",
      "Experience working in Agile teams to support digital transformation projects"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-officer-business-itelligence-techcombank-1628?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " C5 Building Tower, D’Capitale Tower, 119 Tran Duy Hung, Cau Giay, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "Python",
      "Agile"
    ]
  },
  {
    "title": "Senior Data Engineering (Python/Java/SQL)",
    "company": "PVcomBank",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "301-500 nhân viên",
    "linh_vuc": "Dịch Vụ Tài Chính",
    "createdAt": " Đăng 45 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia phân tích, xây dựng các tiêu chuẩn và phương pháp thiết kế về tích hợp dữ liệu, xây dựng giải pháp và phát triển các luồng tích hợp dữ liệu on-premise và on-cloud từ nhiều nguồn khác nhau, nhiều loại dữ liệu khác nhau, dữ liệu thời gian thực, dữ liệu theo định kỳ\nTham gia thiết kế và triển khai hồ dữ liệu (Data Lake), kho dữ liệu doanh nghiệp (Enterprise DataWarehouse & Datamart)\nPhối hợp với các đơn vị liên quan tham gia đánh giá, xây dựng quy định liên quan đến Quản trị và khai thác kho Dữ liệu lớn hiệu quả\nTham gia tiếp nhận, chuyển giao công nghệ, ứng dụng, giải pháp liên quan đến tích hợp dữ liệu\nTiếp nhận và xử lý các yêu cầu hỗ trợ (level 2) khi hệ thống đưa vào khai thác vận hành thực tế; Phối hợp đánh giá hệ thống định kỳ để đưa ra các đề xuất cải tiến sản phẩm, dịch vụ theo khung quản lý chất lượng tại PVcomBank\nTham gia phát triển các dự án chuyển đổi số\nTham gia nghiên cứu, tư vấn và đề xuất áp dụng công nghệ mới nâng cao chất lượng, tối ưu nguồn lực phát triển\nTham gia các khóa đào tạo chuyên ngành theo khung năng lực của PVcomBank theo từng thời kỳ",
      "Tham gia phân tích, xây dựng các tiêu chuẩn và phương pháp thiết kế về tích hợp dữ liệu, xây dựng giải pháp và phát triển các luồng tích hợp dữ liệu on-premise và on-cloud từ nhiều nguồn khác nhau, nhiều loại dữ liệu khác nhau, dữ liệu thời gian thực, dữ liệu theo định kỳ",
      "on-premise",
      "on-cloud",
      "Tham gia thiết kế và triển khai hồ dữ liệu (Data Lake), kho dữ liệu doanh nghiệp (Enterprise DataWarehouse & Datamart)",
      "Data Lake",
      "Enterprise DataWarehouse & Datamart",
      "Phối hợp với các đơn vị liên quan tham gia đánh giá, xây dựng quy định liên quan đến Quản trị và khai thác kho Dữ liệu lớn hiệu quả",
      "Tham gia tiếp nhận, chuyển giao công nghệ, ứng dụng, giải pháp liên quan đến tích hợp dữ liệu",
      "Tiếp nhận và xử lý các yêu cầu hỗ trợ (level 2) khi hệ thống đưa vào khai thác vận hành thực tế; Phối hợp đánh giá hệ thống định kỳ để đưa ra các đề xuất cải tiến sản phẩm, dịch vụ theo khung quản lý chất lượng tại PVcomBank",
      "Tham gia phát triển các dự án chuyển đổi số",
      "chuyển đổi số",
      "Tham gia nghiên cứu, tư vấn và đề xuất áp dụng công nghệ mới nâng cao chất lượng, tối ưu nguồn lực phát triển",
      "Tham gia các khóa đào tạo chuyên ngành theo khung năng lực của PVcomBank theo từng thời kỳ"
    ],
    "yc": [
      "Yêu cầu công việc",
      "YÊU CẦU CÔNG VIỆC",
      "YÊU CẦU CÔNG VIỆC",
      "Thành thạo lập trình R/Python/Java hoặc ngôn ngữ lập trình tương đương\nThành thạo với ngôn ngữ SQL/PLSQL, có kiến thức về các hệ quản trị cơ sở dữ liệu Oracle/MySQL/PostgreSQL và noSQL\nCó tối thiểu 3 năm kinh nghiệm làm việc trong lĩnh vực tài chính ngân hàng hoặc triển khai trong lĩnh vực tài chính ngân hàng\nCó kinh nghiệm xây dựng và thiết kế tiến trình ETL\nCó kinh nghiệm triển khai DataOps\nCó kinh nghiệm triển khai về các mô hình dữ liệu DataWarehouse/Data Lake/DataMart\nCó kinh nghiệm sử dụng công cụ ETL: Spark, Flink, Nifi, IBM DataStage, Oracle ODI,…",
      "Thành thạo lập trình R/Python/Java hoặc ngôn ngữ lập trình tương đương",
      "Thành thạo với ngôn ngữ SQL/PLSQL, có kiến thức về các hệ quản trị cơ sở dữ liệu Oracle/MySQL/PostgreSQL và noSQL",
      "Có tối thiểu 3 năm kinh nghiệm làm việc trong lĩnh vực tài chính ngân hàng hoặc triển khai trong lĩnh vực tài chính ngân hàng",
      "Có kinh nghiệm xây dựng và thiết kế tiến trình ETL",
      "Có kinh nghiệm triển khai DataOps",
      "Có kinh nghiệm triển khai về các mô hình dữ liệu DataWarehouse/Data Lake/DataMart",
      "Có kinh nghiệm sử dụng công cụ ETL: Spark, Flink, Nifi, IBM DataStage, Oracle ODI,…",
      "Ưu tiên các ứng viên",
      "Ưu tiên các ứng viên",
      "Ham học hỏi tìm tòi sáng tạo cái mới\nCó hiểu biết về nghiệp vụ tài chính ngân hàng\nĐã từng triển khai sản phẩm lên AWS\nCó kinh nghiệm làm việc theo mô hình Agile/Scrum\nCó kinh nghiệm triển khai triển khai công cụ tích hợp dữ liệu\nCó kinh nghiệm xử lý dữ liệu thời gian thực",
      "Ham học hỏi tìm tòi sáng tạo cái mới",
      "Có hiểu biết về nghiệp vụ tài chính ngân hàng",
      "Đã từng triển khai sản phẩm lên AWS",
      "Có kinh nghiệm làm việc theo mô hình Agile/Scrum",
      "Có kinh nghiệm triển khai triển khai công cụ tích hợp dữ liệu",
      "Có kinh nghiệm xử lý dữ liệu thời gian thực"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineering-python-java-sql-pvcombank-1847?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 22 Ngô Quyền, Hoan Kiem, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Java",
      "Python",
      "SQL"
    ]
  }
]