[
  {
    "title": "Senior Data Engineer",
    "company": "Creative Force",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Denmark",
    "company_model": "Sản phẩm",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Sản Phẩm Phần Mềm và Dịch Vụ Web",
    "createdAt": " Đăng 1 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are looking for a Senior Data Engineer with a strong technical background in data engineering and a proactive problem-solver with excellent communication skills. You should have a proven ability to build and maintain scalable data architectures and be comfortable working in a dynamic, fast-paced environment. The ideal candidate is passionate about optimizing data pipelines, has strong analytical skills, and is experienced in cloud infrastructure and big data technologies. You thrive in collaborative settings and enjoy working on complex data challenges that enable data-driven decision-making across the organization.",
      "We are looking for a Senior Data Engineer with a strong technical background in data engineering and a proactive problem-solver with excellent communication skills. You should have a proven ability to build and maintain scalable data architectures and be comfortable working in a dynamic, fast-paced environment. The ideal candidate is passionate about optimizing data pipelines, has strong analytical skills, and is experienced in cloud infrastructure and big data technologies. You thrive in collaborative settings and enjoy working on complex data challenges that enable data-driven decision-making across the organization.",
      "Senior Data Engineer",
      " ",
      "Responsibilities",
      "Responsibilities",
      "Responsibilities",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.\nCollaborate with internal teams and external customers to understand data needs and provide high-performance solutions.\nManage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.\nImplement and monitor data quality and integrity checks throughout the data lifecycle.\nBuild and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.",
      "Design, develop, and maintain data pipelines and ETL processes to ensure efficient and scalable data flow.",
      "Collaborate with internal teams and external customers to understand data needs and provide high-performance solutions.",
      "Collaborate with internal teams and external customers to understand data needs and provide high-performance solutions.",
      "Manage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.",
      "Manage cloud-based data infrastructures, ensuring optimal performance and scalability for large datasets.",
      "Implement and monitor data quality and integrity checks throughout the data lifecycle.",
      "Implement and monitor data quality and integrity checks throughout the data lifecycle.",
      "Build and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Build and maintain reporting systems, dashboards, and data models to enable data analysis and insights generation for internal and external stakeholders.",
      "Other responsibilities:",
      "Other responsibilities:",
      "Other responsibilities:",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.\nProvide expertise in designing and optimizing distributed data architectures.\nEnsure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.\nDrive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.\nLead the development of new tools and techniques to enhance the organization’s data capabilities.",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.",
      "Collaborate with cross-functional teams (Product, Development, Customer Success, Finance,...) to integrate data solutions into the organization's products and services.",
      "Provide expertise in designing and optimizing distributed data architectures.",
      "Provide expertise in designing and optimizing distributed data architectures.",
      "Ensure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.",
      "Ensure data systems are secure, reliable, and scalable, with a focus on best practices in cloud infrastructure.",
      "Drive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.",
      "Drive continuous improvements in data management processes, including real-time data processing and streaming using tools like Kafka.",
      "Lead the development of new tools and techniques to enhance the organization’s data capabilities.",
      "Lead the development of new tools and techniques to enhance the organization’s data capabilities."
    ],
    "yc": [
      "Yêu cầu công việc",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.\nStrong technical expertise in database management, statistical analysis, and data visualization.\nStrong knowledge and experience in ETL processes.\nExperience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).\nExperience in managing large-scale databases and optimizing query performance.\nExperience with operational tools like Airflow, Debezium, or Kafka.\nCloud infrastructure and operations (AWS, GCP).\nExperience in Python or another programming language.\nExperience with cloud data warehousing solutions such as Google BigQuery or Snowflake\nHigh-level written and verbal communication skills in English.",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.",
      "05+ years of proven working experience as a Data Engineer, Data Analyst, or similar roles.",
      "Strong technical expertise in database management, statistical analysis, and data visualization.",
      "Strong technical expertise in database management, statistical analysis, and data visualization.",
      "Strong knowledge and experience in ETL processes.",
      "Strong knowledge and experience in ETL processes.",
      "Experience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).",
      "Experience working with large datasets using SQL and Business Intelligence tools (e.g., Looker, Tableau, Google Data Studio).",
      "Experience in managing large-scale databases and optimizing query performance.",
      "Experience in managing large-scale databases and optimizing query performance.",
      "Experience with operational tools like Airflow, Debezium, or Kafka.",
      "Experience with operational tools like Airflow, Debezium, or Kafka.",
      "Cloud infrastructure and operations (AWS, GCP).",
      "Cloud infrastructure and operations (AWS, GCP).",
      "Experience in Python or another programming language.",
      "Experience in Python or another programming language.",
      "Experience with cloud data warehousing solutions such as Google BigQuery or Snowflake",
      "Experience with cloud data warehousing solutions such as Google BigQuery or Snowflake",
      "High-level written and verbal communication skills in English.",
      "High-level written and verbal communication skills in English."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-creative-force-5121?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 2nd Floor, Detech II Tower, 107 Nguyen Phong Sac Str, Cau Giay, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "SQL",
      "Cloud"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Hubble Pte. Ltd",
    "salary_range": "1,000 - 3,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Singapore",
    "company_model": "Sản phẩm",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Bất Động Sản và Xây Dựng",
    "createdAt": " Đăng 5 ngày trước",
    "description": [
      "Mô tả công việc",
      "What you will be doing:",
      "What you will be doing:",
      "Lead the maintenance and development of Hubble’s Data Warehouse and Data pipeline.\nWork with various ETL/ELT pipelines from various data sources.\nCollaborate with product managers and backend engineers to ensure that any changes in the products are accounted for in the data pipelines.\nCollaborate with the DevOps team to ensure that the cost of data processing and storage is optimized for the needs of the company.\nEnsure that the various data products and services are performant and reliable.",
      "Lead the maintenance and development of Hubble’s Data Warehouse and Data pipeline.",
      "Work with various ETL/ELT pipelines from various data sources.",
      "Collaborate with product managers and backend engineers to ensure that any changes in the products are accounted for in the data pipelines.",
      "Collaborate with the DevOps team to ensure that the cost of data processing and storage is optimized for the needs of the company.",
      "Ensure that the various data products and services are performant and reliable."
    ],
    "yc": [
      "Yêu cầu công việc",
      "What we need from you:",
      "What we need from you:",
      "4-5 years experience as a Data Engineer\nExperience working with cloud infrastructure such as Azure, AWS, or GCP.\nExperience working with data processing tools such as Apache Spark, Hadoop, Flink, Snowflake.\nExperience in SQL and Python\nStrong analytical skills in designing and implementing data solutions to address complex challenges from diverse stakeholders.",
      "4-5 years experience as a Data Engineer",
      "Experience working with cloud infrastructure such as Azure, AWS, or GCP.",
      "Experience working with data processing tools such as Apache Spark, Hadoop, Flink, Snowflake.",
      "Experience in SQL and Python",
      "Strong analytical skills in designing and implementing data solutions to address complex challenges from diverse stakeholders."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-hubble-pte-ltd-4546?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 261 Hoang Van Thu st, Tan Binh, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "English"
    ]
  },
  {
    "title": "Mid/Senior Data Analytics Engineer (HCL x ANZ Bank)",
    "company": "HCL Vietnam Company Limited",
    "salary_range": "1,500 - 2,496 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "India",
    "company_model": "Thuê ngoài",
    "company_size": "501-1000 nhân viên",
    "linh_vuc": "Thuê Ngoài Phát Triển Phần Mềm",
    "createdAt": " Đăng 9 ngày trước",
    "description": [
      "Mô tả công việc",
      "About the job",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "We highly appreciate your interest in this position of HCL Vietnam. After reviewing all applications, only qualified candidates will be contacted for the next steps within 15 days from date of submission.",
      "\n ",
      "",
      "JOB TITLE: Analytics Engineer (Mid level)",
      "JOB TITLE:",
      "JOB LOCATION: HCMC",
      "JOB LOCATION",
      "ABOUT HCL VIETNAM COMPANY LIMITED",
      "ABOUT HCL VIETNAM COMPANY LIMITED",
      "HCL Vietnam Company Limited belongs to HCLTech.",
      "HCLTech is a global technology company, home to more than 223,400 people across 60 countries,",
      "delivering industry-leading capabilities centered around digital, engineering, cloud, and AI, powered by a broad portfolio of technology services and products. We work with clients across all major verticals, providing industry solutions for Financial Services, Manufacturing, Life Sciences and Healthcare, Technology and Services, Telecom and Media, Retail and CPG, and Public Services. Consolidated revenues as of 12 months ending June 2023 totaled $12.8 billion. To learn how we can supercharge progress for you, visit",
      "Our Vietnam-based offices:",
      "Our Vietnam-based offices:",
      "Our Vietnam-based offices:",
      "• Hanoi Office: Level 13-17, Leadvisors Tower, 643 Pham Van Dong Street, Co Nhue Ward, North",
      "Tu Liem District, Hanoi",
      "• HCMC Office: Level 11, Five Star Tower, 28Bis Mac Dinh Chi Street, Da Kao Ward, District 1, HCMC\n ",
      "",
      "What is your mission?",
      "What is your mission?",
      "As an Analytics Engineer supporting the Data Enablement stream within ANZ Plus, your mission is to design and build the data products required to support operational pipelines as well as reporting, data science and analytics initiatives to drive business decision-making and innovative customer outcomes for the program.",
      "Your key accountability will be to build and maintain data products in our data mesh through engineering best practices using DBT, Python and BigQuery."
    ],
    "yc": [
      "Yêu cầu công việc",
      "What will your day look like:",
      "What will your day look like:",
      "What will your day look like:",
      "Understand user stories supporting a wide array of use cases such as reporting in Tableau, data science or analytics activities, or indeed operational data flows for decisioning and campaign tools \nDesign physical data structures in Google Big Query to optimise efficiency, scalability and consistency in a repeatable manner \nCatalogue and document metadata on available data sources and communicate rationale for modelling decisions made \nWork closely with the team to ensure data models align with stakeholder expectations and practical engineering patterns in DBT and Terraform \nProfile incoming source data (batch and real-time event) to deeply understand data, contribute to data integration specifications and help to build robust and future-proof models \nParticipate in the continuous improvement of data assets and governance processes to enable customers to easily access the data they need ",
      "Understand user stories supporting a wide array of use cases such as reporting in Tableau, data science or analytics activities, or indeed operational data flows for decisioning and campaign tools ",
      "Design physical data structures in Google Big Query to optimise efficiency, scalability and consistency in a repeatable manner ",
      "Catalogue and document metadata on available data sources and communicate rationale for modelling decisions made ",
      "Work closely with the team to ensure data models align with stakeholder expectations and practical engineering patterns in DBT and Terraform ",
      "Profile incoming source data (batch and real-time event) to deeply understand data, contribute to data integration specifications and help to build robust and future-proof models ",
      "Participate in the continuous improvement of data assets and governance processes to enable customers to easily access the data they need ",
      "What will you bring?",
      "What will you bring?",
      "What will you bring?",
      "To grow and be successful in this role, you will ideally bring the following:",
      "To grow and be successful in this role, you will ideally bring the following:",
      "From 4 years experience\nExcellent English communication skills \nExcellent SQL, data analysis and data profiling skills \nProven success designing and/or building BI/DW or ETL solutions, especially using data transformation tools such as DBT or Dataform \nDemonstrated experience with data pipeline orchestration and/or configuration as code \nExposure to data in cloud-native environments \nAn appreciation for difficult problems and to work autonomously on complex tasks \nThe Analytics Engineer role is a midpoint between Data Analyst and Data Engineer; you need to ‘care’ about the data itself, not just the pipelines, but also be comfortable with engineering practices such as source control, tagging, CI/CD and automated testing using Python. ",
      "From 4 years experience",
      "From 4 years experience",
      "Excellent English communication skills ",
      "Excellent English communication skills ",
      "Excellent SQL, data analysis and data profiling skills ",
      "Proven success designing and/or building BI/DW or ETL solutions, especially using data transformation tools such as DBT or Dataform ",
      "Demonstrated experience with data pipeline orchestration and/or configuration as code ",
      "Exposure to data in cloud-native environments ",
      "An appreciation for difficult problems and to work autonomously on complex tasks ",
      "The Analytics Engineer role is a midpoint between Data Analyst and Data Engineer; you need to ‘care’ about the data itself, not just the pipelines, but also be comfortable with engineering practices such as source control, tagging, CI/CD and automated testing using Python. ",
      "The Analytics Engineer role is a midpoint between Data Analyst and Data Engineer;",
      "At ANZ a growth mindset is at the heart of our culture and we actively encourage people to try new things. If this role interests you and you feel you have most of these things in your toolbox, we’d love to hear from you.",
      "At ANZ a growth mindset is at the heart of our culture and we actively encourage people to try new things. If this role interests you and you feel you have most of these things in your toolbox, we’d love to hear from you."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/mid-senior-data-analytics-engineer-hcl-x-anz-bank-hcl-vietnam-company-limited-0852?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Level 11, Five Star Tower, 28Bis Mac Dinh Chi Street, Da Kao Ward, District 1, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Data Analyst",
      "Python",
      "SQL"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Global Fashion Group",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "United Kingdom",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "May mặc và Thời Trang",
    "createdAt": " Đăng 10 ngày trước",
    "description": [
      "Mô tả công việc",
      "Global Fashion Group is the leading fashion and lifestyle destination in growth markets across LATAM, SEA and ANZ. From our people to our customers and partners, we exist to empower everyone to express their true selves through fashion. Our three e-commerce platforms: Dafiti, ZALORA and THE ICONIC connect an assortment of international, local and own brands to over 800 million consumers from diverse cultures and lifestyles. GFG’s platforms provide seamless and inspiring customer experiences from discovery to delivery, powered by art & science that is infused with unparalleled local knowledge. As part of the Group’s vision is to be the #1 online destination for fashion & lifestyle in growth markets, we are committed to doing this responsibly by being people and planet positive across everything we do. ",
      " ",
      "ABOUT THE TEAM",
      "ABOUT THE TEAM",
      "At GFG, technology is core to long-term success and is a crucial enabler of a great customer experience. We are a mix of experts in fashion, logistics, data analytics, marketing and design, guided by business consultants and tech geniuses - everyone contributes to the success of GFG.",
      " ",
      "ABOUT THE ROLE ",
      "ABOUT THE ROLE ",
      "Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.\nWork in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.",
      "Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.",
      "Work in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team. The role is based in our Vietnam office.",
      "THE IMPACT YOU’LL MAKE ",
      "THE IMPACT YOU’LL MAKE ",
      "Data at GFG never stops growing and the team also never stops learning, innovating and expanding so that we can bring in or build the latest and best tools and technologies. In this role, you will be able to create strategic data models, develop and maintain data architecture used to power high-impact business initiatives that contribute to the overall growth and strategy for GFG."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Bachelor or Master degree in Computer Science or a related technical discipline",
      "Be familiar with:",
      "Be familiar with:",
      "Data structures & algorithms\nData modelling\nBasic machine learning algorithms\nFollowing languages: SQL, Python, R, Java/Scala\nAny of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift\nCloud technologies: AWS, GCP (BigQuery)",
      "Data structures & algorithms",
      "Data modelling",
      "Basic machine learning algorithms",
      "Following languages: SQL, Python, R, Java/Scala",
      "Any of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift",
      "Cloud technologies: AWS, GCP (BigQuery)",
      "2. Be knowledgeable in:",
      "2. Be knowledgeable in:",
      "Object oriented design and design patterns\nLarge-scale distributed systems\nHadoop, Spark and Pandas or similar processing engines\nJupyter Notebook or Zeppelin\nApache Airflow, Apache Superset",
      "Object oriented design and design patterns",
      "Large-scale distributed systems",
      "Hadoop, Spark and Pandas or similar processing engines",
      "Jupyter Notebook or Zeppelin",
      "Apache Airflow, Apache Superset",
      "3. Good to have:",
      "3. Good to have:",
      "Knowledge of data visualization\nGood background in statistics\nKnowledge in data analysis, data mining, or machine learning\nExperience working with big data",
      "Knowledge of data visualization",
      "Good background in statistics",
      "Knowledge in data analysis, data mining, or machine learning",
      "Experience working with big data"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-global-fashion-group-0305?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Copac Square Building, 12 Tôn Đản, phường 13, District 4, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "AWS"
    ]
  },
  {
    "title": "Senior Data Engineer (Python, SQL, Database)",
    "company": "DATAPOT",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 12 giờ trước",
    "description": [
      "Mô tả công việc",
      "About Datapot Analytics:",
      "About Datapot Analytics:",
      "Datapot Analytics is a leading data analytics group known for its cutting-edge solutions and innovative approach to data management. With a strong foundation in leveraging advanced analytics and AI technologies, Datapot Analytics has consistently delivered exceptional results for clients across various industries. Our mission is to empower businesses with actionable insights and drive data-driven decision-making.",
      "Datapot Analytics is a leading data analytics group known for its cutting-edge solutions and innovative approach to data management. With a strong foundation in leveraging advanced analytics and AI technologies, Datapot Analytics has consistently delivered exceptional results for clients across various industries. Our mission is to empower businesses with actionable insights and drive data-driven decision-making.",
      "Introducing KHantix:",
      "Introducing KHantix:",
      "Introducing KHantix:",
      "KHantix, a new venture under the Datapot Analytics umbrella, is set to revolutionize the data analytics landscape. Specializing in innovative solutions using Microsoft Data Analytics services, KHantix is dedicated to building a data-native company in the AI-first era. Our focus is on harnessing the power of data to create impactful solutions that drive business success",
      "KHantix, a new venture under the Datapot Analytics umbrella, is set to revolutionize the data analytics landscape. Specializing in innovative solutions using Microsoft Data Analytics services, KHantix is dedicated to building a data-native company in the AI-first era. Our focus is on harnessing the power of data to create impactful solutions that drive business success",
      "Job Description: Project Manager",
      "Job Description: ",
      "Job Description: ",
      "Project Manager",
      "Key Responsibilities:",
      "Key Responsibilities:",
      "Design, develop, and maintain scalable data pipelines and ETL processes to support data integration and analytics. \nImplement and optimize data storage solutions using Microsoft Fabric, Azure Synapse, Azure Data Factory, and other Microsoft data services. \nDevelop and maintain data models, databases, and data warehouses to ensure data accuracy and availability. \nEnsure data quality and integrity through rigorous testing and validation procedures. \nStay updated with the latest trends and best practices in data engineering and analytics. ",
      "Design, develop, and maintain scalable data pipelines and ETL processes to support data integration and analytics. ",
      "Implement and optimize data storage solutions using Microsoft Fabric, Azure Synapse, Azure Data Factory, and other Microsoft data services. ",
      "Develop and maintain data models, databases, and data warehouses to ensure data accuracy and availability. ",
      "Ensure data quality and integrity through rigorous testing and validation procedures. ",
      "Stay updated with the latest trends and best practices in data engineering and analytics. "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Qualifications:",
      "Qualifications:",
      "Bachelor’s or Master’s degree in Computer Science, Data, or a related field. \n5+ years of experience in data engineering, with a strong focus on Microsoft data analytics solutions. \nProficiency in SQL, Python, and other programming languages relevant to data engineering.\nStrong understanding of data modeling, ETL processes, and data warehousing concepts. \nExcellent problem-solving skills and attention to detail. ",
      "Bachelor’s or Master’s degree in Computer Science, Data, or a related field. ",
      "5+ years of experience in data engineering, with a strong focus on Microsoft data analytics solutions. ",
      "Proficiency in SQL, Python, and other programming languages relevant to data engineering.",
      "Strong understanding of data modeling, ETL processes, and data warehousing concepts. ",
      "Excellent problem-solving skills and attention to detail. ",
      "(*) Preferred Qualifications:",
      "(*) Preferred Qualifications:",
      "Experience with big data technologies such as Databricks, Hadoop and Spark. \nKnowledge of AI/ML techniques. \nFamiliarity with data governance and security best practices. ",
      "Experience with big data technologies such as Databricks, Hadoop and Spark. ",
      "Knowledge of AI/ML techniques. ",
      "Familiarity with data governance and security best practices. "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-sql-database-datapot-3746?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Tầng 9, toà nhà Gardenia, số 48 Bích Câu, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "Database",
      "SQL"
    ]
  },
  {
    "title": "[DI6] Senior Data Engineer (SQL, Python) – MSB - 1Y565",
    "company": "MSB",
    "salary_range": "1,000 - 2,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 2 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.\nRà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.\nThường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.\nHỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.\nXây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.",
      "Rà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.",
      "Thường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.",
      "Hỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.",
      "Xây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin\nCó kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...\nCó kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL\nÍt nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)\nHiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới\nKhả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc\nKhả năng thiết kế Tích hợp dữ liệu thời gian thực",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin",
      "Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...",
      "Có kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL",
      "Ít nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)",
      " Java/Python/Scala, SQL",
      "Hiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới",
      "Khả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc",
      "Khả năng thiết kế Tích hợp dữ liệu thời gian thực"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/di6-senior-data-engineer-sql-python-msb-1y565-msb-0227?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " ROX Tower, 54A Nguyen Chi Thanh, phuong Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "Python",
      "Java"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "Picket Homes",
    "salary_range": "Start from $3000",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "United States",
    "company_model": "Sản phẩm",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Bất Động Sản và Xây Dựng",
    "createdAt": " Đăng 7 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are seeking an exceptional Senior Data Engineer to work closely with executives, real estate professionals, product managers, and engineers to develop and implement software solutions for managing listings and property data. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.  ",
      "We are seeking an exceptional Senior Data Engineer to work closely with executives, real estate professionals, product managers, and engineers to develop and implement software solutions for managing listings and property data. This person must embrace an unusual combination of advanced technologies and extreme pragmatism to solve hard problems quickly, iterating on improvement relentlessly.  "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Requirements",
      "Requirements",
      "3+ years of professional experience in data engineering and software development\nExpertise in Java or Kotlin\nProficiency in relational database\nUnderstanding of SW lifecycle including best practices in testing and deployment \nFamiliarity with Git, Linux, AWS, and other software tools and cloud services\nTechnical writing ability, including visual diagramming tools\nBachelor's degree from a top engineering university",
      "3+ years of professional experience in data engineering and software development",
      "Expertise in Java or Kotlin",
      "Proficiency in relational database",
      "Understanding of SW lifecycle including best practices in testing and deployment ",
      "Familiarity with Git, Linux, AWS, and other software tools and cloud services",
      "Technical writing ability, including visual diagramming tools",
      "Bachelor's degree from a top engineering university",
      "---",
      "Expectations",
      "Expectations",
      "Expectations",
      "In month one, complete company onboarding, and build your own development plan for ownership of an area in our data platform team.\nWithin the first three months, research and implement new features for our data ingestion services. Build out at least one new feature with another team member.\nWithin six months, create a roadmap for improving ingestion processes, documentation, and integration with other services, then begin executing it.",
      "In month one, complete company onboarding, and build your own development plan for ownership of an area in our data platform team.",
      "Within the first three months, research and implement new features for our data ingestion services. Build out at least one new feature with another team member.",
      "Within six months, create a roadmap for improving ingestion processes, documentation, and integration with other services, then begin executing it.",
      "Set your sights on the following by the end of your first year:",
      "Set your sights on the following by the end of your first year:",
      "Set your sights on the following by the end of your first year:",
      "Take ownership of ingestion services and continuously iterate to improve their reliability and robustness.  \nHelp build out the team through recruiting, high-bar interviewing, onboarding, and mentoring.\nGain a comprehensive understanding of real estate, housing, geographies, and market characteristics to enhance your decision-making and implementations. ",
      "Take ownership of ingestion services and continuously iterate to improve their reliability and robustness.  ",
      "Help build out the team through recruiting, high-bar interviewing, onboarding, and mentoring.",
      "Gain a comprehensive understanding of real estate, housing, geographies, and market characteristics to enhance your decision-making and implementations. ",
      " "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-picket-homes-1253?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 4th Floor, No 2 Alley 1 Lane 26 Do Quang Street Trung Hoa Ward, Cau Giay District Hanoi, Vietnam, Cau Giay, Ha Noi "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Java",
      "Kotlin",
      "Linux"
    ]
  },
  {
    "title": "Senior Data Engineer",
    "company": "NAB Innovation Centre Vietnam",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Australia",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 17 ngày trước",
    "description": [
      "Mô tả công việc",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      "By applying for the above position, you accept and agree that your personal data and any information stated in the attached curriculum vitae (CV) will be used and processed by ITViec and NAB Vietnam for recruitment purposes. The storage and processing of such information will comply with the applicable laws of Vietnam, and the policies and procedures of ITViec and NAB Vietnam regarding personal data, as amended from time to time.",
      " ",
      "About the job:",
      "About the job:",
      "At NAB, we are at the forefront of building a next-generation Security Information and Event Management (SIEM) system. As part of this mission, we are seeking a dynamic and experienced engineers to join our newly formed SIEM Engineering team. This is a unique opportunity to be on the ground floor of a new capability, where you will play a crucial role in shaping the future of SIEM capabilities at NAB.",
      " ",
      "JOB RESPONSIBILITIES",
      "JOB RESPONSIBILITIES",
      "Use security best practices in the undertaking of their day-to-day responsibilities, \nIdentify and implement process improvements.\nActively identify, report, and implement risk remediation tasks as appropriate to your role. \nDesign, develop and implement solutions in collaboration with other technical teams.",
      "Use security best practices in the undertaking of their day-to-day responsibilities, ",
      "Identify and implement process improvements.",
      "Actively identify, report, and implement risk remediation tasks as appropriate to your role. ",
      "Design, develop and implement solutions in collaboration with other technical teams.",
      "You will:",
      "Engineer data supporting Cyber Security outcomes.\nExhibit and maintain high engineering standards, including documentation.\nContribute to setting the level of urgency within the team in addressing issues.\nHave a solid understanding of data processing and storage, alerting and searching techniques and technologies to guide and validate the work of your team\nAdhere to rigorous processes.",
      "Engineer data supporting Cyber Security outcomes.",
      "Exhibit and maintain high engineering standards, including documentation.",
      "Contribute to setting the level of urgency within the team in addressing issues.",
      "Have a solid understanding of data processing and storage, alerting and searching techniques and technologies to guide and validate the work of your team",
      "Adhere to rigorous processes."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tertiary qualification in a Technology discipline or related field\nQualifications and/or certifications in data, engineering and/or cybersecurity are highly valued.\n5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM\nExperience with a subset of the following technologies:\nAmazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)\nIdeally experience with Cyber Security domain.",
      "Tertiary qualification in a Technology discipline or related field",
      "Qualifications and/or certifications in data, engineering and/or cybersecurity are highly valued.",
      "5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM",
      "5+ years experience with building, and maintaining ETL pipelines, data lakes or SIEM",
      "Experience with a subset of the following technologies:\nAmazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)",
      "Amazon SNS/SQS\nAzure Service Bus\nAzure Event Hubs\nApache Kafka\nWindows Event Forwarder\nSyslog\nCribl\nSplunk, including Data Modelling\nData lake (eg, Snowflake or Data Bricks)",
      "Amazon SNS/SQS",
      "Azure Service Bus",
      "Azure Event Hubs",
      "Apache Kafka",
      "Windows Event Forwarder",
      "Syslog",
      "Cribl",
      "Splunk, including Data Modelling",
      "Data lake (eg, Snowflake or Data Bricks)",
      "Ideally experience with Cyber Security domain.",
      "Cyber Security domain."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-nab-innovation-centre-vietnam-4522?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " TNR Tower, 54A Nguyen Chi Thanh, Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Data Analyst",
      "Cloud",
      "Security"
    ]
  },
  {
    "title": "Data Engineer / Senior Data Engineer",
    "company": "Eyepax IT Consulting Company Limited",
    "salary_range": "1,000 - 2,250 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Singapore",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "151-300 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 19 ngày trước",
    "description": [
      "Mô tả công việc",
      "Eyepax is a global software solutions firm with a strong international presence spanning over 17 years. Headquartered in Singapore, we have development centers in Sri Lanka and Vietnam. As a member of our Vietnam team, you will join a workforce of over 180 IT professionals. ",
      "We seek a talented and motivated Data Engineer/Senior Data Engineer to join our development team. As a Data Engineer/Senior Data Engineer, you will play a key role in developing and maintaining the data infrastructure that supports our client’s operations. This is an excellent opportunity to contribute to the development and success of our organization. Proficiency in English communication is essential for seamless collaboration with teammates and clients worldwide."
    ],
    "yc": [
      "Yêu cầu công việc",
      "Experience and Responsibilities:",
      "Experience and Responsibilities:",
      "Experience and Responsibilities:",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.\nA minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.\nDesign, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.\nCollaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).\nProficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).\nExperience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.\nSkilled in data analysis and able to interpret complex data sets and derive actionable insights.\nDefine and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.\nEnsure data quality, reliability, and security by supporting Data Governance processes.\nAble to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.\nKnowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.\nA basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.\nAssist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.",
      "Bachelor’s or master's in Data science, Data Engineering, Computer Science or a related field.",
      "A minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.",
      "A minimum of 2 years for DE and 4 years SDE experience specifically in a data engineering role, including working with large-scale data platforms.",
      "Design, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.",
      "Design, develop, and maintain robust data pipelines to support analytics and business needs by ingesting and processing data from various sources into the cloud platform.",
      "Collaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).",
      "Collaborate with cross-functional teams, including Data Science and Data Product teams, to define data models, architecture, and transformations using tools like DBT (SQL/Jinja).",
      "Proficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).",
      "Proficient in Python-based data engineering (Mage) and SQL (MySQL, PostgreSQL, NoSQL).",
      "Experience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.",
      "Experience with big data tools like Databricks and Spark and cloud-based platforms like BigQuery for large-scale data analytics.",
      "Skilled in data analysis and able to interpret complex data sets and derive actionable insights.",
      "Skilled in data analysis and able to interpret complex data sets and derive actionable insights.",
      "Define and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.",
      "Define and standardize data assets to ensure high-quality data delivery while supporting the design and development of scalable data architectures and integration solutions.",
      "Ensure data quality, reliability, and security by supporting Data Governance processes.",
      "Ensure data quality, reliability, and security by supporting Data Governance processes.",
      "Able to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.",
      "Able to understand cloud-based infrastructure and have experience working with data visualization tools such as Tableau, Looker Studio, and Power BI.",
      "Knowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.",
      "Knowledge of ETL/ELT best practices, data warehousing concepts, and experience with data modeling techniques.",
      "A basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.",
      "A basic understanding of Google Tag Manager and Google Analytics setup, testing, and validation is a plus.",
      "Assist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Assist the team leader in project management and provide business-as-usual (BAU) support services.",
      "Qualification and Personal Characteristics:",
      "Qualification and Personal Characteristics:",
      "Qualification and Personal Characteristics:",
      "Strong problem-solving and analytical skills with attention to detail.\nExcellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.\nAbility to learn new technologies quickly and innovate within the data space.\nStrong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.\nSelf-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes.",
      "Strong problem-solving and analytical skills with attention to detail.",
      "Strong problem-solving and analytical skills with attention to detail.",
      "Excellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.",
      "Excellent communication and teamwork skills, with the ability to work collaboratively with user departments and vendors.",
      "Ability to learn new technologies quickly and innovate within the data space.",
      "Ability to learn new technologies quickly and innovate within the data space.",
      "Strong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.",
      "Strong customer service mindset, with the ability to train and mentor team members, identifying skills and gaps.",
      "Self-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes.",
      "Self-initiative, proactive, and forward-thinking, focusing on continuously improving data platforms and processes."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/junior-senior-data-engineer-python-sql-aws-eyepax-it-consulting-company-limited-0402?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 2nd floor 15 Đ. Lê Thánh Tôn, Bến Nghé, District 1, Ho Chi Minh "
    ],
    "workplace": "Linh hoạt",
    "skills": [
      "Python",
      "SQL",
      "Scala"
    ]
  },
  {
    "title": "Middle/Senior Data Engineer (Azure, Databricks)",
    "company": "TechSoft",
    "salary_range": "Negotiable",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Dịch vụ và Tư vấn giải pháp",
    "company_size": "51-150 nhân viên",
    "linh_vuc": "Dịch Vụ và Tư Vấn IT",
    "createdAt": " Đăng 23 ngày trước",
    "description": [
      "Mô tả công việc",
      "Are you up to becoming a Data Engineer at TechSoft?",
      "a Data Engineer ",
      " ",
      "We are looking for a data engineer with a couple of years of experience. You hold a bachelor’s or master’s degree in computer science or equal through experience. You are part of a multidisciplinary scrum team that takes ownership of designing and implementing our platform and its software features, with a focus on data analytics. As a data engineer analyst, you’ll be building data pipelines and dataset quality monitoring to make raw data usable by stakeholders. ",
      " ",
      "You’ll have at least 5 years of experience working as a Data Engineer. On a personal level, you are passionate about data analytics and are always up to date in terms of new technology. You have a systematic approach in your way of working and are able to keep a sense of perspective of the different tasks. We expect you to have good communication skills and the ability to engage with many different people both internally in the organization and externally. You have excellent written and verbal communication skills in English.  ",
      " ",
      " ",
      "Key Responsibilities:",
      "Key Responsibilities",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features\nDesign, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. \nBuild the data foundations needed for a strong BI service to business and R&D stakeholders\nTransform our raw data into ready-to-use, high-quality datasets and build mechanisms to monitor their quality.\nSuggest, discuss, and define process improvements, and how can we improve our way of working ",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features",
      "Be a part of a multi-disciplinary and international SCRUM team that takes ownership of designing and implementing our platform and its software features",
      "Design, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. ",
      "Design, develop, and maintain scalable data pipelines on Azure using Azure Data Factory, Databricks, and other relevant tools. ",
      "Build the data foundations needed for a strong BI service to business and R&D stakeholders",
      "Transform our raw data into ready-to-use, high-quality datasets and build mechanisms to monitor their quality.",
      "Suggest, discuss, and define process improvements, and how can we improve our way of working "
    ],
    "yc": [
      "Yêu cầu công việc",
      "Education: Bachelor's or Master's degree in Computer Science or related fields, or equivalent experience.\nExperience:\nAt least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence \nTechnical Skills:\nKnowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.\nPersonal Traits:\nExcellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Education: Bachelor's or Master's degree in Computer Science or related fields, or equivalent experience.",
      "Education",
      "Computer Science",
      "Experience:\nAt least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "Experience",
      "At least 5 years of experience working as a Data Engineer.\nExpertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.\nExperience with SCRUM teams and Agile methodology.\nExperience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "At least 5 years of experience working as a Data Engineer.",
      "5 years of experience",
      "Expertise in Azure, Databricks, SQL, Python, Apache Spark, PySpark, and orchestration tools, and BI tools.",
      "Expertise",
      "Databricks",
      "SQL",
      "Python",
      "Apache Spark",
      "PySpark",
      "orchestration tools, ",
      "and BI tools",
      "Experience with SCRUM teams and Agile methodology.",
      "SCRUM teams",
      "Agile methodology",
      "Experience with Continuous Integration Principles and related tools e.g. Jira, Confluence ",
      "Continuous Integration Principles",
      "Technical Skills:\nKnowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.",
      "Technical Skills",
      "Knowledge of DevOps practices and tools like Docker, Kubernetes is a plus.\nCertification in Azure Data Engineering or related areas is highly desirable.",
      "Knowledge of DevOps practices and tools like Docker, Kubernetes is a plus.",
      "DevOps practices",
      "Docker",
      "Kubernetes",
      "Certification in Azure Data Engineering or related areas is highly desirable.",
      "Certification",
      "Personal Traits:\nExcellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Personal Traits",
      "Excellent communication skills, both written and verbal, with fluency in English.\nSelf-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy \nDetermination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision ",
      "Excellent communication skills, both written and verbal, with fluency in English.",
      "communication skills",
      "English",
      "Self-responsibility and commitment in meeting project objectives and ensuring software validation activities are conducted with timeliness, thoroughness and accuracy ",
      "Self-responsibility ",
      "commitment",
      "Determination and sound technical judgment in problem solving, analytical techniques, develops new / creative test designs, and can work independently with little supervision "
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-sql-database-techsoft-2436?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 45 Nguyễn Hữu An, Son Tra, Da Nang "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Cloud",
      "Azure",
      "Data Analyst"
    ]
  },
  {
    "title": "Middle - Senior Data Engineer (Azure, Databricks)",
    "company": "EMESOFT",
    "salary_range": "You'll love it",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Thuê ngoài",
    "company_size": "1-50 nhân viên",
    "linh_vuc": "Thuê Ngoài Phát Triển Phần Mềm",
    "createdAt": " Đăng 24 ngày trước",
    "description": [
      "Mô tả công việc",
      "We are looking for a skilled Data Engineer with expertise in Python, Pytest, and Databricks. This role involves designing, developing, and maintaining data processing systems and pipelines, utilizing Python’s full capabilities and Databricks’ cloud-based analytics platform. ",
      "Data Engineer",
      "Python",
      "Pytest",
      "Databricks",
      "The position requires a deep understanding of data engineering principles and the ability to apply them effectively in a dynamic environment.",
      "RESPONSIBILITIES",
      "RESPONSIBILITIES",
      "Cooperate with the infrastructure team to design, develop, and maintain the customers’ data platform.\nBuild data pipelines to extract, transform, and load data from a variety of sources\nBuild data warehouses and data lakes to store and manage data\nDevelop and deploy data processing and analytics tools\nWork with the infrastructure team to build data warehouse or data lake to support customers for data driven decisions.\nStay up-to-date on the latest data technologies",
      "Cooperate with the infrastructure team to design, develop, and maintain the customers’ data platform.",
      "Build data pipelines to extract, transform, and load data from a variety of sources",
      "Build data warehouses and data lakes to store and manage data",
      "Develop and deploy data processing and analytics tools",
      "Work with the infrastructure team to build data warehouse or data lake to support customers for data driven decisions.",
      "Stay up-to-date on the latest data technologies"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Bachelor’s degree in computer science, data science, or a related field.\nMinimum of 3 years of hands-on experience in data engineering, demonstrating practical proficiency.\nStrong understanding of data engineering principles and practices, with a focus on real-world application.\nProven experience with a variety of data technologies, including Databricks and Azure Data Factory (ADF), AWS Glue or similar cloud services\nProficiency in SQL and excellent programming skills in Python (pandas, polars, pyspark) or Scala, including unit testing with tools like pytest.\nExperience with cloud computing platforms such as Azure/AWS/GCP, with preference given to candidates holding relevant cloud data certifications (Azure Data Engineer Associate, AWS Certified Data Engineer, Google Professional Data Engineer)..\nFamiliarity with big data technologies, such as Hadoop, Spark, and Hive, is highly desirable.\nExperience with data visualization tools like PowerBI or Tableau is a plus.\nDemonstrated ability to learn and apply new technologies in a hands-on manner quickly.\nCapacity to work both independently and collaboratively within a team, showcasing strong problem-solving skills and initiative.",
      "Bachelor’s degree in computer science, data science, or a related field.",
      "Minimum of 3 years of hands-on experience in data engineering, demonstrating practical proficiency.",
      "hands-on",
      "Strong understanding of data engineering principles and practices, with a focus on real-world application.",
      "Proven experience with a variety of data technologies, including Databricks and Azure Data Factory (ADF), AWS Glue or similar cloud services",
      "Databricks",
      "Azure Data Factory (ADF)",
      "Proficiency in SQL and excellent programming skills in Python (pandas, polars, pyspark) or Scala, including unit testing with tools like pytest.",
      "Experience with cloud computing platforms such as Azure/AWS/GCP, with preference given to candidates holding relevant cloud data certifications (Azure Data Engineer Associate, AWS Certified Data Engineer, Google Professional Data Engineer)..",
      "Familiarity with big data technologies, such as Hadoop, Spark, and Hive, is highly desirable.",
      "Experience with data visualization tools like PowerBI or Tableau is a plus.",
      "PowerBI",
      "Tableau",
      "Demonstrated ability to learn and apply new technologies in a hands-on manner quickly.",
      "Capacity to work both independently and collaboratively within a team, showcasing strong problem-solving skills and initiative."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/mid-sr-data-engineer-python-sql-azure-databricks-emesoft-2141?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " Floor 8, 596 Cong Hoa, Ward 13, Tan Binh, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "SQL",
      "Azure"
    ]
  },
  {
    "title": "Senior Data Engineer (Python, Data Warehouse, Alert)",
    "company": "Simple Tech Investment",
    "salary_range": "1,800 - 2,500 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "301-500 nhân viên",
    "linh_vuc": "Dịch Vụ Tài Chính",
    "createdAt": " Đăng 31 ngày trước",
    "description": [
      "Mô tả công việc",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.\nClarify requirements with Developers and Business users to build a data mart that meets functional/non-functional business requirements.\nDesign and maintain optimal data pipeline architecture.\nSupport internal training and proper documentation ensuring the successful onboarding of new team members.\nImplement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nDevelop efficient software code for multiple use cases leveraging Spark and Big Data Technologies for various use cases built on the platform.",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.",
      "Build the infrastructure",
      "required",
      "Clarify requirements with Developers and Business users to build a data mart that meets functional/non-functional business requirements.",
      "Clarify requirements",
      "build a data mart",
      "Design and maintain optimal data pipeline architecture.",
      "Design and maintain optimal data pipeline",
      "Support internal training and proper documentation ensuring the successful onboarding of new team members.",
      "Support internal",
      "Implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.",
      "Implement internal process improvements",
      "Develop efficient software code for multiple use cases leveraging Spark and Big Data Technologies for various use cases built on the platform.",
      "Develop efficient software code"
    ],
    "yc": [
      "Yêu cầu công việc",
      " At least 4+ years’ experience working as a Senior Data Engineer role, ETL with large amounts of data. Bachelor’s degree in related technical discipline.\nExperience with data warehousing architecture, Data modeling and ETL data pipeline. \nExperience in monitoring data quality, code factor, Data quality control alert, ...\nExperience with using the following software/tool in the big data field.\nNoSQL and OLAP database: MongoDB, Elastic search, etc.\nGood at programming languages: Scala, Python, Java.\nExperience in the data testing process.\nExperience in performing root cause analysis, identify problems and propose recommendations for improvement.\nStrong organizational and multitasking skills with the ability to balance competing priorities.\nFundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP).",
      " At least 4+ years’ experience working as a Senior Data Engineer role, ETL with large amounts of data. Bachelor’s degree in related technical discipline.",
      "+ years’ experience ",
      " of data. Bachelor’s degree ",
      ".",
      "Experience with data warehousing architecture, Data modeling and ETL data pipeline. ",
      "Experience with data warehousing architecture, Data modeling",
      "Experience in monitoring data quality, code factor, Data quality control alert, ...",
      "Experience with using the following software/tool in the big data field.",
      "Experience with using the following software/tool in the big data field.",
      "NoSQL and OLAP database: MongoDB, Elastic search, etc.",
      "Good at programming languages: Scala, Python, Java.",
      "Good at ",
      " Scala, Python, Java.",
      "Experience in the data testing process.",
      "Experience in the data testing process.",
      "Experience in performing root cause analysis, identify problems and propose recommendations for improvement.",
      "Experience in performing root cause analysis, identify problems and propose recommendations for improvement.",
      "Strong organizational and multitasking skills with the ability to balance competing priorities.",
      "Strong organizational and multitasking skills ",
      ".",
      "Fundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP).",
      "Fundamental knowledge of modern cloud computing platforms and concepts is a plus (AWS/GCP)."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-python-data-warehouse-alert-simple-tech-investment-1826?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " 402 Nguyễn Thị Minh Khai, District 3, Ho Chi Minh "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Python",
      "Database",
      "NoSQL"
    ]
  },
  {
    "title": "[DI6] Senior Data Engineer (SQL, Python) – MSB - 1Y565",
    "company": "MSB",
    "salary_range": "1,000 - 2,000 USD",
    "timeWork": "Thứ 2 - Thứ 6",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Ngân Hàng",
    "createdAt": " Đăng 23 ngày trước",
    "description": [
      "Mô tả công việc",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.\nRà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.\nThường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.\nHỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.\nXây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn",
      "Tham gia nghiên cứu, phát triển và áp dụng các giải pháp công nghệ liên quan tới ETL, Tích hợp khai thác và phát triển dữ liệu lớn.",
      "Rà soát thiết kế hệ thống dữ liệu hiện tại để tìm ra các ưu nhược điểm, đánh giá rủi ro của mô hình hiện tại và đề xuất, tổ chức triển khai các giải pháp khắc phục, nâng cao.",
      "Thường xuyên cập nhật các công nghệ mới, mô hình dữ liệu hiện đại, so sánh phân tích đưa ra các giải pháp tối ưu phù hợp để có thể áp dụng vào hệ thống hiện tại của Ngân hàng.",
      "Hỗ trợ phân tích, tư vấn về giải pháp, thiết kế dữ liệu lớn cho các hệ thống, ứng dụng được phát triển và triển khai tại Ngân hàng.",
      "Xây dựng, kiểm soát, triển khai và nâng cấp hệ thống ETL, tích hợp, khai thác và phát triển dữ liệu lớn"
    ],
    "yc": [
      "Yêu cầu công việc",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin\nCó kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...\nCó kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL\nÍt nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)\nHiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới\nKhả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc\nKhả năng thiết kế Tích hợp dữ liệu thời gian thực",
      "Tốt nghiệp Đại học Công nghệ thông tin, Khoa học máy tính, Hệ thống thông tin, Thông tin truyền thông, Toán-Tin",
      "Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, sử dụng các mã nguồn mở trên hệ sinh thái Hadoop ecosystem như spark, spark-streaming, spark-SQL, hive, hbase, Kafka...",
      "Có kinh nghiệm làm việc cơ sở dữ liệu lớn, thành thạo ngôn ngữ lập trình Cơ sở Dữ liệu cấu trúc hoặc phi cấu trúc SQL, NoSQL",
      "Ít nhất 4 năm lập trình ngôn ngữ lập trình Java/Python/Scala, SQL trong việc sử lý dữ liệu (Data Analyst)",
      " Java/Python/Scala, SQL",
      "Hiểu về các mô hình thiết kế dữ liệu lớn, công nghệ trong lĩnh vực dữ liệu đang là xu hướng thế giới",
      "Khả năng phân tích, thiết kế hệ thống dữ liệu lớn, tối ưu job xử lý dữ liệu có cấu trúc và phi cấu trúc",
      "Khả năng thiết kế Tích hợp dữ liệu thời gian thực"
    ],
    "linkJob": "https://itviec.com/viec-lam-it/di6-senior-data-engineer-sql-python-msb-1y565-msb-4254?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " ROX Tower, 54A Nguyen Chi Thanh, phuong Lang Thuong, Dong Da, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "SQL",
      "Python",
      "Java"
    ]
  },
  {
    "title": "Senior Data Engineer (Onprem/Signing Bonus 0.5 Month)",
    "company": "Giao Hàng Tiết Kiệm",
    "salary_range": "2,500 - 3,000 USD",
    "timeWork": "Thứ 2 - Thứ 7",
    "timeOt": "Không có OT",
    "nation": "Vietnam",
    "company_model": "Sản phẩm",
    "company_size": "1000+ nhân viên",
    "linh_vuc": "Vận Tải, Logistics và Kho Hàng",
    "createdAt": " Đăng 44 ngày trước",
    "description": [
      "Mô tả công việc",
      "– Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ big data: Hadoop\necosystem, kafka, spark, …;\n– Nghiên cứu và triển khai các công nghệ lưu trữ và tính toán trên hệ thống bigdata;\n– Vận hành, triển khai các job ETL, tổng hợp dữ liệu;\n– Xây dựng & triển khai hệ thống phát hiện bất thường, hệ thống Hồ sơ khách hàng đảm bảo hiệu năng và tính sẵn sàng cao;\n– Làm việc với các team khác: Vận hành, Sản phẩm, BA.",
      "– Tham gia phát triển và triển khai các dịch vụ sử dụng các công nghệ big data: Hadoop",
      "",
      "ecosystem, kafka, spark, …;",
      "",
      "– Nghiên cứu và triển khai các công nghệ lưu trữ và tính toán trên hệ thống bigdata;",
      "",
      "– Vận hành, triển khai các job ETL, tổng hợp dữ liệu;",
      "",
      "– Xây dựng & triển khai hệ thống phát hiện bất thường, hệ thống Hồ sơ khách hàng đảm bảo hiệu năng và tính sẵn sàng cao;",
      "",
      "– Làm việc với các team khác: Vận hành, Sản phẩm, BA."
    ],
    "yc": [
      "Yêu cầu công việc",
      "– Có khả năng lập trình chuyên sâu java/python/scala;\n– Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, BI, sử dụng các mã nguồn mở như Hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;\n– Lập trình thông thạo spark, spark-streaming;\n– Có kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc\nLambda/Kappa/Data Lake;\n– Có kinh nghiệm xây dựng các hệ thống customer 360 đảm bảo hiệu năng và tính sẵn sàng cao;\n– Tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.",
      "– Có khả năng lập trình chuyên sâu java/python/scala;",
      "",
      "– Có kinh nghiệm làm việc về các hệ thống big data, Data-warehouse, BI, sử dụng các mã nguồn mở như Hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;",
      "",
      "– Lập trình thông thạo spark, spark-streaming;",
      "",
      "– Có kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc",
      "",
      "Lambda/Kappa/Data Lake;",
      "",
      "– Có kinh nghiệm xây dựng các hệ thống customer 360 đảm bảo hiệu năng và tính sẵn sàng cao;",
      "",
      "– Tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới."
    ],
    "linkJob": "https://itviec.com/viec-lam-it/senior-data-engineer-onprem-signing-bonus-0-5-month-giao-hang-tiet-kiem-4951?lab_feature=preview_jd_page",
    "linkCompany": "",
    "crawlTime": "26/10/2024",
    "address": [
      " GHTK Building, đường Phạm Hùng, phường Mễ Trì, quận Nam Từ Liêm, thành phố Hà Nội, Nam Tu Liem, Ha Noi "
    ],
    "workplace": "Tại văn phòng",
    "skills": [
      "Java",
      "Python",
      "MySQL"
    ]
  }
]